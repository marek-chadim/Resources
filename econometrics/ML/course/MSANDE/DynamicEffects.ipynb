{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ab49937",
   "metadata": {},
   "source": [
    "# Dynamic Treatment Regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f034bc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "\n",
    "# generate dynamic data\n",
    "def gen_data(alpha, A, B, c, n, d, tau1=None, tau2=None):\n",
    "    S1 = np.random.normal(0, 1, size=(n, d))\n",
    "    if tau1 is None:\n",
    "        D1 = np.random.binomial(1, scipy.special.expit(S1 @ alpha))\n",
    "    else:\n",
    "        D1 = tau1 * np.ones(n)\n",
    "    S2 = S1 @ A.T + D1.reshape(-1, 1) @ B + np.random.normal(0, 1, size=(n, d))\n",
    "    if tau2 is None:\n",
    "        D2 = np.random.binomial(1, scipy.special.expit(S2 @ alpha))\n",
    "    else:\n",
    "        D2 = tau2 * np.ones(n)\n",
    "    Y = D2 + S2 @ c + np.random.normal(0, 1, size=(n,))\n",
    "    return S1, D1, S2, D2, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f21c2aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance parameters\n",
    "d = 4\n",
    "alpha = np.random.uniform(-1, 1, size=d)\n",
    "A = np.random.uniform(-1, 1, size=(d, d))\n",
    "B = np.random.uniform(-1, 1, size=(1, d))\n",
    "c = np.random.uniform(-1, 1, size=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb9cb4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5957640334260048"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observational treatment regime mean outcome\n",
    "n = 1000000\n",
    "np.mean(gen_data(alpha, A, B, c, n, d)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8ff1b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011186618066241865"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expected value of counterfactual treatment regime (0, 0)\n",
    "n = 1000000\n",
    "V00 = np.mean(gen_data(alpha, A, B, c, n, d, 0, 0)[-1])\n",
    "V00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2460ae64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2194222032891435"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expected value of counterfactual treatment regime (1, 1)\n",
    "n = 1000000\n",
    "V11 = np.mean(gen_data(alpha, A, B, c, n, d, 1, 1)[-1])\n",
    "V11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8351af74",
   "metadata": {},
   "source": [
    "# Generate Observed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1b2b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000\n",
    "S1, D1, S2, D2, y = gen_data(alpha, A, B, c, n, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b0529",
   "metadata": {},
   "source": [
    "# Wrong Identification by Conditioning of Effects with OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "622382bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "effects = LinearRegression().fit(np.column_stack([D1, D2, S1, S2]), y).coef_[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2580cb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 0.1178, True: 0.0011\n"
     ]
    }
   ],
   "source": [
    "# estimated expected value of counterfactual treatment regime (0, 0)\n",
    "V00hat = np.mean(y - effects[0] * D1 - effects[1] * D2)\n",
    "print(f'Estimate: {V00hat:.4f}, True: {V00:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15943f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 1.1118, True: 1.2194\n"
     ]
    }
   ],
   "source": [
    "# estimated expected value of counterfactual treatment regime (1, 1)\n",
    "V11hat = np.mean(y - effects[0] * (D1 - 1) - effects[1] * (D2 - 1))\n",
    "print(f'Estimate: {V11hat:.4f}, True: {V11:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82245869",
   "metadata": {},
   "source": [
    "# G-Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c651ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "def cntf(S1, D1, S2, D2, y, tau1, tau2, modely1, modely2):\n",
    "    n = S1.shape[0]\n",
    "    my2 = modely2.fit(np.column_stack([D2, S2]), y)\n",
    "    Yadj = my2.predict(np.column_stack([tau2 * np.ones(n), S2]))\n",
    "\n",
    "    my1 = modely1.fit(np.column_stack([D1, S1]), Yadj)\n",
    "    Yadj = my1.predict(np.column_stack([tau1 * np.ones(n), S1]))\n",
    "\n",
    "    return np.mean(Yadj)\n",
    "\n",
    "short_cntf = lambda tau1, tau2: cntf(S1, D1, S2, D2, y, tau1, tau2, LinearRegression(), LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8db01024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 0.0081, True: 0.0011\n"
     ]
    }
   ],
   "source": [
    "print(f'Estimate: {short_cntf(0, 0):.4f}, True: {V00:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0ed7855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 1.2160, True: 1.2194\n"
     ]
    }
   ],
   "source": [
    "print(f'Estimate: {short_cntf(1, 1):.4f}, True: {V11:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87aec28",
   "metadata": {},
   "source": [
    "# Doubly (Multiply) Robust Estimation and Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b695081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "def drcntf(S1, D1, S2, D2, y, tau1, tau2, modely1, modely2, modeld1, modeld2):\n",
    "    n = S1.shape[0]\n",
    "    \n",
    "    my2 = modely2.fit(np.column_stack([D2, S2]), y)\n",
    "    resy2 = y - my2.predict(np.column_stack([D2, S2]))\n",
    "    Yadj2 = my2.predict(np.column_stack([tau2 * np.ones(n), S2]))\n",
    "    \n",
    "    md2 = modeld2.fit(S2, D2)\n",
    "    prop2 = md2.predict_proba(S2)[:, 1]\n",
    "    ips2 = tau2 * (D2 == 1) / prop2 + (1 - tau2) * (D2 == 0) / (1 - prop2)\n",
    "\n",
    "    my1 = modely1.fit(np.column_stack([D1, S1]), Yadj2)\n",
    "    resy1 = Yadj2 - my1.predict(np.column_stack([D1, S1]))\n",
    "    Yadj1 = my1.predict(np.column_stack([tau1 * np.ones(n), S1]))\n",
    "\n",
    "    md1 = modeld1.fit(S1, D1)\n",
    "    prop1 = md1.predict_proba(S1)[:, 1]\n",
    "    ips1 = tau1 * (D1 == 1) / prop1 + (1 - tau1) * (D1 == 0) / (1 - prop1)\n",
    "\n",
    "    dr = Yadj1 + ips1 * resy1 + ips1 * ips2 * resy2\n",
    "    return np.mean(dr), np.std(dr) / np.sqrt(n)\n",
    "\n",
    "short_drcntf = lambda tau1, tau2: drcntf(S1, D1, S2, D2, y, tau1, tau2,\n",
    "                                         LinearRegression(), LinearRegression(),\n",
    "                                         LogisticRegression(C=1000), LogisticRegression(C=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6865b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: -0.0311 (0.0488), True: 0.0011\n"
     ]
    }
   ],
   "source": [
    "V00hat, V00se = short_drcntf(0, 0)\n",
    "print(f'Estimate: {V00hat:.4f} ({V00se:.4f}), True: {V00:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cb664d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 1.2167 (0.0542), True: 1.2194\n"
     ]
    }
   ],
   "source": [
    "V11hat, V11se = short_drcntf(1, 1)\n",
    "print(f'Estimate: {V11hat:.4f} ({V11se:.4f}), True: {V11:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9569915",
   "metadata": {},
   "source": [
    "# G-Estimation: Dynamic Partialling Out (Neyman Orthogonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad5e9636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import scipy.linalg\n",
    "\n",
    "def dynplr(S1, D1, S2, D2, y, tau1, tau2, modely1, modely2, modeld1, modeld2):\n",
    "    n = S1.shape[0]\n",
    "\n",
    "    psi = np.zeros((n, 3))\n",
    "    J = np.zeros((3, 3))\n",
    "    \n",
    "    # Estimate second period treatment effect using Partialling Out\n",
    "    my2 = modely2.fit(S2, y)\n",
    "    resy2 = y - my2.predict(S2)\n",
    "    md2 = modeld2.fit(S2, D2)\n",
    "    resD2 = D2 - md2.predict_proba(S2)[:, 1]\n",
    "    delta2 = np.mean(resy2 * resD2) / np.mean(resD2**2) # effect of D2\n",
    "    \n",
    "    # moment function for delta2\n",
    "    psi[:, 2] = (resy2 - delta2 * resD2) * resD2\n",
    "    # jacobian of moment\n",
    "    J[2, 2] = - np.mean(resD2**2)\n",
    "\n",
    "    # Adjust the outcome for second period treatment\n",
    "    Yadj2 = y - delta2 * (D2 - tau2)\n",
    "\n",
    "    # Estimate first period treatment effect using Partialling Out\n",
    "    my1 = modely1.fit(S1, Yadj2)\n",
    "    resy1 = Yadj2 - my1.predict(S1)\n",
    "    md1 = modeld1.fit(S1, D1)\n",
    "    resD1 = D1 - md1.predict_proba(S1)[:, 1]\n",
    "    delta1 = np.mean(resy1 * resD1) / np.mean(resD1**2) # effect of D1\n",
    "    \n",
    "    # moment function for delta1\n",
    "    psi[:, 1] = (resy1 - delta1 * resD1) * resD1\n",
    "    # jacobian of moment\n",
    "    J[1, 1:] = - np.array([np.mean(resD1**2), np.mean(resD1 * (D1 - tau1))])\n",
    "    \n",
    "    # Adjust the outcome for first period treatment\n",
    "    Yadj1 = Yadj2 - delta1 * (D1 - tau1)\n",
    "    \n",
    "    # Mean counterfactual value estimate\n",
    "    theta = np.mean(Yadj1)\n",
    "    \n",
    "    # moment for theta\n",
    "    psi[:, 0] = Yadj1 - theta\n",
    "    # jacobian of moment\n",
    "    J[0, :] = - np.array([1, np.mean(D1 - tau1), np.mean(D2 - tau2)])\n",
    "    \n",
    "    # calculating covariance of (theta, delta1, delta2)\n",
    "    Jinv = scipy.linalg.pinv(J)\n",
    "    Sigma = psi.T @ psi / n\n",
    "    V = Jinv @ Sigma @ Jinv.T\n",
    "\n",
    "    return theta, np.sqrt(V[0, 0] / n)\n",
    "\n",
    "short_dynplr = lambda tau1, tau2: dynplr(S1, D1, S2, D2, y, tau1, tau2,\n",
    "                                         LinearRegression(), LinearRegression(),\n",
    "                                         LogisticRegression(C=1000), LogisticRegression(C=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a854af60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 0.0149 (0.0407), True: 0.0011\n"
     ]
    }
   ],
   "source": [
    "V00hat, V00se = short_dynplr(0, 0)\n",
    "print(f'Estimate: {V00hat:.4f} ({V00se:.4f}), True: {V00:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6247bc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 1.2094 (0.0404), True: 1.2194\n"
     ]
    }
   ],
   "source": [
    "V11hat, V11se = short_dynplr(1, 1)\n",
    "print(f'Estimate: {V11hat:.4f} ({V11se:.4f}), True: {V11:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff0b24",
   "metadata": {},
   "source": [
    "# Project Star Example Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9dbe8f",
   "metadata": {},
   "source": [
    "Project star was a longitudinal study where students were randomized in small or regular sized classrooms from kindergarten till grade 4. We will use here the first two classes, k and grade 1 and examine the effect of the small classroom interventions in kindergarden and grade 1 on test scores at the end of grade 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b34772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "URL = 'https://raw.githubusercontent.com/gsbDBI/ExperimentData/master/Project%20STAR/STAR_Students.tab'\n",
    "df = pd.read_csv(URL, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9d47afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1cols = ['gender', 'race', 'birthmonth', 'birthyear',\n",
    "        'gkschid', 'gksurban', 'gktgen',\n",
    "        'gktrace', 'gkthighdegree', 'gktcareer',\n",
    "        'gktyears', 'gkfreelunch', 'gkrepeat',\n",
    "        'gkspeced', 'gkspecin']\n",
    "D1cols = ['gkclasstype']\n",
    "y1cols = ['gktreadss', 'gktmathss']\n",
    "S2cols = ['gender', 'race', 'birthmonth', 'birthyear',\n",
    "        'g1schid', 'g1surban', 'g1tgen',\n",
    "        'g1trace', 'g1thighdegree', 'g1tcareer',\n",
    "        'g1tyears', 'g1freelunch',\n",
    "        'g1speced', 'g1specin']\n",
    "D2cols = ['g1classtype']\n",
    "y2cols = ['g1treadss', 'g1tmathss']\n",
    "df = df[S1cols + D1cols + y1cols + S2cols + D2cols + y2cols]\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9881e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "D1 = 1.0 * (df[D1cols].values.flatten() == 1) # is small class\n",
    "S1 = df[S1cols]\n",
    "D2 = 1.0 * (df[D2cols].values.flatten() == 1) # is small class\n",
    "S2 = df[S2cols + S1cols + y1cols + D1cols]\n",
    "y = np.sum(df[y2cols].values, axis=1) # total of reading and math scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "456e8854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, LogisticRegressionCV\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "short_drcntf = lambda tau1, tau2: drcntf(S1, D1, S2, D2, y, tau1, tau2,\n",
    "                                         LassoCV(), LassoCV(),\n",
    "                                         LogisticRegressionCV(), LogisticRegressionCV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d37badd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate(0, 0): 1058.1835 (2.4596)\n",
      "Estimate(0, 1): 1063.9774 (1.5556)\n",
      "Estimate(1, 0): 1072.5690 (1.7907)\n",
      "Estimate(1, 1): 1090.5339 (6.4301)\n"
     ]
    }
   ],
   "source": [
    "for tau1 in [0, 1]:\n",
    "    for tau2 in [0, 1]:\n",
    "        Vhat, Vse = short_drcntf(tau1, tau2)\n",
    "        print(f'Estimate({tau1}, {tau2}): {Vhat:.4f} ({Vse:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bda6364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_dynplr = lambda tau1, tau2: dynplr(S1, D1, S2, D2, y, tau1, tau2,\n",
    "                                         LassoCV(), LassoCV(),\n",
    "                                         LogisticRegressionCV(), LogisticRegressionCV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8584e702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate(0, 0): 1059.2718 (1.8834)\n",
      "Estimate(0, 1): 1069.4421 (2.4312)\n",
      "Estimate(1, 0): 1070.8131 (2.4958)\n",
      "Estimate(1, 1): 1080.9834 (2.7793)\n"
     ]
    }
   ],
   "source": [
    "for tau1 in [0, 1]:\n",
    "    for tau2 in [0, 1]:\n",
    "        Vhat, Vse = short_dynplr(tau1, tau2)\n",
    "        print(f'Estimate({tau1}, {tau2}): {Vhat:.4f} ({Vse:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0a2402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
