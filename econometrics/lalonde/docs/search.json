[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tutorial for ‘LaLonde (1986) after Nearly Four Decades: Lessons Learned’",
    "section": "",
    "text": "Welcome!\nThis is a Quarto Book (Rbookdown previously) tutorial condensing the analysis from Imbens & Xu (2024).\nWe reflect on five key lessons from the methodological literature following LaLonde’s 1986 study:\nRevisiting LaLonde’s analysis, we present how modern methods could enhance causal inference using data compiled by Rajeev Dehejia and Sadek Wahba (Dehejia and Wahba 1999, 2002) and survey data of lottery players in Imbens, Rubin, and Sacerdote (2001). Hereafter, we denote the former dataset as the LaLonde-Dehejia-Wahba (LDW) data, and the latter as IRS data. Our findings highlight that causal inference with observational data demands rigorous ( i ) examination of the assignment process, ( ii ) assessment of overlap, and ( iii ) execution of validation checks. This tutorial streamlines the methodology used in Imbens & Xu (2024), making it easier for readers to replicate the study and apply its techniques in their own research. In addition, we supplement a complementary application of our analytics with the original LaLonde (1986) data after the LDW analysis to further demonstrate and validate our methodologies.\nReference: Imbens, Guido and Yiqing Xu (2024). “LaLonde (1986) after Nearly Four Decades: Lessons Learned.” arXiv:2406.00827.\nAcknowledgement: We thank Zihan Xie and Jinwen Wu for their excellent research assistance, which makes this tutorial possible."
  },
  {
    "objectID": "index.html#data-files",
    "href": "index.html#data-files",
    "title": "Tutorial for ‘LaLonde (1986) after Nearly Four Decades: Lessons Learned’",
    "section": "Data Files",
    "text": "Data Files\nImbens and Xu (2024) uses the following datasets, which are based on LaLonde (1986), Dehejia and Wahba (1999), Calónico and Smith (2017), and Imbens, Rubin, and Sacerdote (2001).\n\n\n\n\n\n\n\n\n\nData.files\nDetails\nFile_Type\nExperimental\n\n\n\n\nnsw.dta\nNSW experimental data, used in LaLonde (1986)\nStata\nYes\n\n\nnsw_dw.dta\nSubset of NSW experimental data, used in Dehejia & Wahba (1999)\nStata\nYes\n\n\ncps_controls.dta\nCPS-SSA-1 controls, used in both papers\nStata\nNo\n\n\npsid_controls.dta\nPSID-1 controls, used in both papers\nStata\nNo\n\n\nlottery.RData\nData of lottery winners, used in Imbens, Rubin & Sacerdote (201)\nR\nNo\n\n\nNSW_AFDC_CS.dta\nReconstructed NSW AFDC female samples\nStata\nBoth\n\n\n\n\n\n\n\nCalónico, Sebastian, and Jeffrey Smith. 2017. “The Women of the National Supported Work Demonstration.” Journal of Labor Economics 35 (S1): S65–97.\n\n\nDehejia, Rajeev H, and Sadek Wahba. 1999. “Causal Effects in Nonexperimental Studies: Reevaluating the Evaluation of Training Programs.” Journal of the American Statistical Association 94 (448): 1053–62.\n\n\n———. 2002. “Propensity Score-Matching Methods for Nonexperimental Causal Studies.” Review of Economics and Statistics 84 (1): 151–61.\n\n\nFirpo, Sergio. 2007. “Efficient Semiparametric Estimation of Quantile Treatment Effects.” Econometrica 75 (1): 259–76.\n\n\nImbens, Guido W, Donald B Rubin, and Bruce I Sacerdote. 2001. “Estimating the Effect of Unearned Income on Labor Earnings, Savings, and Consumption: Evidence from a Survey of Lottery Players.” American Economic Review, 778–94.\n\n\nLaLonde, Robert J. 1986. “Evaluating the Econometric Evaluations of Training Programs with Experimental Data.” The American Economic Review, 604–20."
  },
  {
    "objectID": "01-Start.html#installation",
    "href": "01-Start.html#installation",
    "title": "\n1  Getting Started\n",
    "section": "\n1.1 Installation",
    "text": "1.1 Installation\nSeveral R packages are required for subsequent data analysis and visualization. The code below checks for all required messages and installs the missing ones. After the installation, call to load the packages.\nPackages: “haven”, “labelled”, “estimatr”, “grf”, “ggplot2”, “Matching”, “hbal”, “CBPS”, “DoubleML”, “mlr3learners”, “fixest”, “qte”, “sensemakr”\n\nCode# required packages\npackages &lt;- c(\"haven\", \"labelled\", \"Matching\", \"grf\", \"sensemakr\", \"qte\",\n    \"estimatr\", \"CBPS\", \"hbal\", \"DoubleML\", \"mlr3learners\", \"mlr3\",\"fixest\", \"ggplot2\")\n\n# install packages\ninstall_all &lt;- function(packages) {\n  installed_pkgs &lt;- installed.packages()[, \"Package\"]\n  for (pkg in packages) {\n    if (!pkg %in% installed_pkgs) {\n      install.packages(pkg)\n    }\n  }\n}\n\ninstall_all(packages)\n\n# load packages\nlibrary(haven)\nlibrary(labelled)\nlibrary(grf)\nlibrary(Matching)\nlibrary(estimatr)\nlibrary(hbal)\nlibrary(CBPS)\nlibrary(DoubleML)\nlibrary(mlr3learners)\nlibrary(mlr3)\nlibrary(fixest)\nlibrary(ggplot2)\nlibrary(qte)\nlibrary(sensemakr)"
  },
  {
    "objectID": "01-Start.html#wrapper-functions",
    "href": "01-Start.html#wrapper-functions",
    "title": "\n1  Getting Started\n",
    "section": "\n1.2 Wrapper Functions",
    "text": "1.2 Wrapper Functions\nNext, we outline the 10 wrapper functions designed to address 6 research objectives. The table below offers a brief overview of each category. Clicking “More” will direct you to a subsequent section with detailed explanations as well as the full code.\n\n\n\n\n\n\nNote\n\n\n\nTo use the wrapper functions, the simplest method is to source the R script with the following code. Please note, this is NOT the official replication file, and you should carefully review the code before using it.\n\n\n\nCodesource(\"https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE\")\n\n\nNow, you should see the functions in the Environment section (if you are using RStudio).\n\n1.2.1 Overview\n\n\nFunction\nDescription\nCode\n\n\n\n\nplot_hist(), love.plot() and assess_overlap()\n\nEvaluates and visualizes the overlap in propensity scores and covariate balance between treated and control groups.\nMore\n\n\npsmatch()\nPerforms 1:1 matching based on estimated propensity scores.\nMore\n\n\n\nestimate_all() and plot_coef()\n\nComputes and visualizes the Average Treatment Effect on the Treated (ATT) using a number of estimators.\nMore\n\n\n\ncatt() and plot_catt()\n\nCalculates and visualizes the Conditional Average Treatment Effect on the Treated (CATT) using Augmented Inverse Probability Weighting (AIPW)-Generalized Random Forests (GRF).\nMore\n\n\n\nest_qte() and plot_qte()\n\nEstimates and visualizes the Quantile Treatment Effect on the Treated (QTET) using a doubly-robust estimator.\nMore\n\n\nsens_ana()\nImplements sensitivity analyses using contour plots.\nMore\n\n\n\n\n\n1.2.2 plot_hist() , love.plot() & assess_overlap()\n\nplot_hist() visualizes the distribution of propensity scores across treated and control groups, with options to adjust for odds and density.\n\nCodeplot_hist &lt;- function(data, var, treat, main = NULL, odds = FALSE,\n                      breaks = 40, density = TRUE, xlim = NULL, ylim = NULL,\n                      xlab = NULL, text.size = 0.8) {\n  ntr &lt;- sum(data[, treat] == 1)\n  nco &lt;- sum(data[, treat] == 0)\n  if (odds == TRUE) {\n    data[, var] &lt;- log(data[, var]/(1-data[, var]))\n    if (is.null(xlab) == TRUE) {xlab &lt;- \"Log Odds\"}\n  } else {\n    if (is.null(xlab) == TRUE) {xlab &lt;- \"Propensity Score\"}\n  }\n  if (is.null(xlim)) {\n    if (odds == TRUE) {\n      xlim &lt;- range(data[, var])\n      cat(xlim)\n    } else {\n      xlim &lt;- c(0,1)\n    }\n  }\n  intervals &lt;- seq(xlim[1], xlim[2], length.out = breaks + 1)\n  h0 &lt;- as.numeric(table(cut(data[data[,treat]==0, var],\n                             breaks = intervals, include.lowest = TRUE)))\n  h1 &lt;- as.numeric(table(cut(data[data[,treat]==1, var],\n                             breaks = intervals, include.lowest = TRUE)))\n  if (density == TRUE) {\n    h0 &lt;- h0/sum(h0); h1 &lt;- h1/sum(h1)\n  }\n  s &lt;- cbind.data.frame(h0, h1)\n  if (is.null(ylim)) {\n    ylim.max &lt;- max(s$h0, s$h1) * 1.2\n    ylim &lt;- c(-ylim.max, ylim.max)\n  }\n  par(mar = c(4, 4, 1, 1))\n  barplot(s$h0 * -1, names.arg = sprintf(\"%.2f\", intervals[-1]),\n          col = \"#AAAAAA80\", main = main, cex.lab = 1.3,\n          ylim = ylim, xlab = xlab, cex.axis = 1.2, cex.names = 1.2,\n          ylab = \"Density\", border = NA, axes = TRUE)\n  barplot(s$h1, col = \"#ff000080\", add = TRUE,\n          border = NA, cex.axis = 1.2)\n  abline(h = 0, col = \"gray60\", lty = 2, lwd = 1.5)\n  axis(1, at = seq(1, 60, length.out = breaks/2), labels = FALSE)\n  usr &lt;- par(\"usr\")\n  user_x &lt;- usr[1] + 0.03 * (usr[2] - usr[1])\n  user_y &lt;- usr[3] + 0.92 * (usr[4] - usr[3])\n  text(user_x, user_y, paste(\"Ntr = \", ntr), pos = 4, cex = text.size)\n  text(user_x, user_y - 0.05 * (usr[4] - usr[3]), paste(\"Nco = \", nco),\n       pos = 4, cex = text.size)\n  box()\n}\n\n\nlove.plot() is a summary plot of covariate balance before and after conditioning popularized by Dr. Thomas E. Love.\n\nCode\nlove.plot &lt;- function(data_pre, data_post, treat, covar, threshold = 0.1, title = \"Love.Plot\") {\n  \n  standardized_diff &lt;- function(data, treat, covar) {\n    treated &lt;- data[data[[treat]] == 1, ]\n    control &lt;- data[data[[treat]] == 0, ]\n    \n    std_diff &lt;- sapply(covar, function(var) {\n      mean_treated &lt;- mean(treated[[var]], na.rm = TRUE)\n      mean_control &lt;- mean(control[[var]], na.rm = TRUE)\n      sd_pooled &lt;- sqrt((var(treated[[var]], na.rm = TRUE) + var(control[[var]], na.rm = TRUE)) / 2)\n      (mean_treated - mean_control) / sd_pooled\n    })\n    \n    return(std_diff)\n  }\n  \n  std_diff_pre &lt;- standardized_diff(data_pre, treat, covar)\n  std_diff_post &lt;- standardized_diff(data_post, treat, covar)\n  \n  love_data &lt;- data.frame(\n    Variable = rep(covar, 2),\n    Std_Diff = c(std_diff_pre, std_diff_post),\n    Matching = rep(c(\"Pre-Matching\", \"Post-Matching\"), each = length(covar))\n  )\n  \n  p &lt;- ggplot(love_data, aes(x = Variable, y = Std_Diff, color = Matching)) +\n    geom_point(size = 3) +\n    geom_hline(yintercept = 0, linetype = \"dashed\", color = \"black\") +\n    geom_hline(yintercept = threshold, linetype = \"dashed\", color = \"red\") +\n    geom_hline(yintercept = -threshold, linetype = \"dashed\", color = \"red\") +\n    coord_flip() +\n    labs(title = title, x = \"Covariates\", y = \"Standardized Mean Differences\") +\n    theme_minimal() +\n    theme(\n      panel.border = element_rect(color = \"black\", fill = NA, size = 1)\n    )\n  \n  return(p)\n}\n\n\nassess_overlap() estimates the overlap in propensity scores between the treatment group and the control group. It fits a probability forest to estimate propensity scores based on covariates (cov) and treatment indicators in the input dataset. Then, the function adjusts propensity scores close to zero to facilitate further calculations. Finally, it calls plot_hist to visualize the distribution of the propensity scores or their log odds, depending on the odds parameter.\n\nCodeassess_overlap &lt;- function(data, treat, cov, odds = TRUE, num.trees = NULL, seed = 1234, breaks = 50, xlim = NULL, ylim = NULL) {\n  if(is.null(num.trees))\n  {\n    p.forest1 &lt;- probability_forest(X = data[, cov],\n                                    Y = as.factor(data[,treat]), seed = seed)\n  }\n  else\n  {\n    p.forest1 &lt;- probability_forest(X = data[, cov],\n                                    Y = as.factor(data[,treat]), seed = seed, num.trees = num.trees)\n  }\n  data$ps_assoverlap &lt;- p.forest1$predictions[,2]\n  #range(lcps.plus$ps)\n  data$ps_assoverlap[which(abs(data$ps_assoverlap) &lt;= 1e-7)] &lt;- 1e-7\n  #range(lcps.plus$ps)\n  if(odds == TRUE)\n  {\n    plot_hist(data, \"ps_assoverlap\", treat, odds = TRUE, breaks = breaks,\n          density = TRUE, main = \"\", xlim = xlim, ylim = ylim)\n  }\n  else\n  {\n    plot_hist(data, \"ps_assoverlap\", treat, odds = FALSE, breaks = breaks,\n              density = TRUE, main = \"\", xlim = c(0, 1), ylim = ylim)\n  }\n  return(data)\n}\n\n\nArguments\nData\n\n\ndata: The targeted dataset.\n\nvar: The variable of interest to plot.\n\ntreat: The (binary) treatment indicator documented in the dataset (usually 0 for control and 1 for treated).\n\nAnalysis\n\n\nodds: If TRUE, the function transforms the variable into log odds.\n\ncov: Covariates used to estimate the propensity score.\n\nnum.trees: Number of trees to use in the probability forest. If NULL, a default is used.\n\nseed: Seed for reproducibility.\n\nPlotting\n\n\nbreaks, density, xlim, ylim, xlab: Parameters for histogram aesthetics and scaling.\n\ntext.size: The size of the text for additional information on the plot.\n\n\n\n\n1.2.3 psmatch()\n\npsmatch() function matches observations in the treatment group with those in the control group according to propensity scores. The matching procedure is executed on a one-to-one basis without replacement. The function then yields a subset of the original dataset with only the matched cases.\n\nCodepsmatch &lt;- function(data, Y, treat, cov, num.trees = 4000, seed = 1234, replace = FALSE, estimand = \"ATT\")\n{\n  set.seed(seed) # need to set seed b/c tie-breaking is random\n  data$psmatch &lt;- probability_forest(X = data[, cov],\n                                Y = as.factor(data[, treat]), seed = seed, num.trees = num.trees)$predictions[,2]\n  mout &lt;- Match(Y = data[,Y], Tr = data[,treat], X = data$psmatch, estimand = estimand, M = 1,\n                BiasAdjust = FALSE, replace=replace, ties = FALSE)\n  data &lt;- data[c(mout$index.treated, mout$index.control), ]\n  return(data)\n}\n\n\nArguments\nThe parameters used in plot_hist and assess_overlap are carried through for the inputs for the psmatch function. Note that, we differentiate psmatch by using Y to represents the outcome variable of interest. Additional parameters are:\n\n\nreplace: A boolean indicating whether sampling of controls is with replacement (default is FALSE).\n\nestimand: The estimand to be estimated, defaulting to ATT.\n\n\n\n\n1.2.4 estimate_all() & plot_coef()\n\nestimate_all() is a comprehensive tool for estimating the Average Treatment Effect on the Treated (ATT) with observational data. Here, we condensed several estimates such as:\n\nDifference in Means\nRegression\nOaxaca Blinder (OM:Reg) and Generalized Random Forests (OM:GRF) as an outcome model\n1: 5 nearest neighbor matching with bias correction, propensity score matching\nInverse Probability Weighting (IPW), Covariate Balancing Propensity Score(CBPS), and Entropy Balancing\nDouble/debiased matching learning using elastic net\nAugmented Inverse Probability Weighting (AIPW) with GRF\n\n\nCodequiet &lt;- function(x) {\n  sink(tempfile())\n  on.exit(sink())\n  invisible(force(x))\n}\n\n# difference in means\ndiff &lt;- function(data, Y, treat) {\n  fml &lt;- as.formula(paste(Y, \"~\", treat))\n  out &lt;- summary(lm_robust(fml, data = data, se_type = \"stata\"))$coefficients[treat, c(1, 2, 5, 6)]\n  return(out) # extract coef, se, ci.lower, ci.upper\n}\n\n\n# regression adjustment\nreg &lt;- function(data, Y, treat, covar) {\n  fml &lt;- as.formula(paste(Y, \"~\", treat, \"+\", paste(covar, collapse = \" + \")))\n  out &lt;- summary(lm_robust(fml, data = data, se_type = \"stata\"))$coefficients[treat, c(1, 2, 5, 6)]\n  # extract coef, se, ci.lower, ci.upper\n  return(out)\n}\n\n# matching\n#library(Matching)\nmatching &lt;- function(data, Y, treat, covar) {\n  m.out &lt;- Match(Y = data[, Y], Tr = data[, treat], X = data[, covar], Z = data[, covar],\n                 estimand = \"ATT\", M = 5, replace = TRUE, ties = TRUE, BiasAdjust = TRUE)\n  out &lt;- c(m.out$est[1], m.out$se[1], m.out$est[1] - 1.96 * m.out$se[1],\n           m.out$est[1] + 1.96 * m.out$se[1])\n  return(out)\n}\n\npsm &lt;- function(data, Y, treat, covar) {\n  ps &lt;- probability_forest(X = data[, covar],\n                           Y = as.factor(data[,treat]), seed = 1234, num.trees = 4000)$predictions[,2]\n  m.out &lt;- Match(Y = data[, Y], Tr = data[, treat], X = matrix(ps, nrow(data), 1),\n                 estimand = \"ATT\", M = 1, replace = FALSE, ties = FALSE, BiasAdjust = FALSE)\n  if (is.null(m.out$se)==FALSE) {\n    se &lt;- m.out$se[1]\n  } else {\n    se &lt;- m.out$se.standard[1]\n  }\n  out &lt;- c(m.out$est[1], se, m.out$est[1] - 1.96 * se,\n           m.out$est[1] + 1.96 * se)\n  return(out)\n}\n\n\n# OM (reg)\nom.reg &lt;- function(data, Y, treat, covar) {\n  tr &lt;- which(data[, treat] == 1)\n  co &lt;- which(data[, treat] == 0)\n  fml &lt;- as.formula(paste(Y, \"~\", paste(covar, collapse = \" + \")))\n  out.co &lt;- lm(fml, data = data[co, ])\n  Y.tr.hat &lt;- predict(out.co, newdata = data[tr, covar, drop = FALSE])\n  newdata &lt;- cbind.data.frame(Y = c(data[tr, Y], Y.tr.hat), treat = rep(c(1, 0), each = length(tr)))\n  out &lt;- summary(lm_robust(Y ~ treat, data = newdata, se_type = \"stata\"))$coefficients[\"treat\", c(1, 2, 5, 6)]\n  return(out)\n}\n\n# OM (grf)\n#library(grf)\nom.grf &lt;- function(data, Y, treat, covar) {\n  tr &lt;- which(data[, treat] == 1)\n  co &lt;- which(data[, treat] == 0)\n  out.co &lt;- regression_forest(X = data[co, covar, drop = FALSE], Y = as.vector(data[co, Y]) )\n  Y.tr.hat &lt;- as.vector(unlist(predict(out.co, newdata = data[tr, covar, drop = FALSE])))\n  newdata &lt;- cbind.data.frame(Y = c(data[tr, Y], Y.tr.hat), treat = rep(c(1, 0), each = length(tr)))\n  out &lt;- summary(lm_robust(Y ~ treat, data = newdata, se_type = \"stata\"))$coefficients[\"treat\", c(1, 2, 5, 6)]\n  return(out)\n}\n\n\n# IPW\nipw &lt;- function(data, Y, treat, covar) {\n  ps &lt;- probability_forest(X = data[, covar, drop = FALSE], Y = as.factor(data[, treat]), seed = 1234)$predictions[,2]\n  fml &lt;- as.formula(paste(Y, \"~\", treat))\n  weights &lt;- rep(1, nrow(data))\n  co &lt;- which(data[, treat] == 0)\n  weights[co] &lt;- ps[co]/(1-ps[co])\n  out &lt;- summary(lm_robust(fml, data = data, weights = weights, se_type = \"stata\"))$coefficients[treat, c(1, 2, 5, 6)]\n  # extract coef, se, ci.lower, ci.upper\n  return(out)\n}\n\n# CBPS\n#library(\"CBPS\")\ncbps &lt;- function(data, Y, treat, covar) {\n  fml &lt;- as.formula(paste(treat, \"~\", paste(covar, collapse = \" + \")))\n  ps &lt;- quiet(CBPS(fml, data = data, standardize = TRUE)$fitted.values)\n  fml &lt;- as.formula(paste(Y, \"~\", treat))\n  weights &lt;- rep(1, nrow(data))\n  co &lt;- which(data[, treat] == 0)\n  weights[co] &lt;- ps[co]/(1-ps[co])\n  out &lt;- summary(lm_robust(fml, data = data, weights = weights, se_type = \"stata\"))$coefficients[treat, c(1, 2, 5, 6)]\n  return(out)\n}\n\n# ebal\n#library(hbal)\nebal &lt;- function(data, Y, treat, covar) {\n  ebal.out &lt;- hbal::hbal(Y = Y, Treat = treat, X = covar,  data = data, expand.degree = 1)\n  out &lt;- hbal::att(ebal.out, dr = FALSE)[1, c(1, 2, 5, 6)]\n  return(out)\n}\n\n# hbal\n# hbal &lt;- function(data, Y, treat, covar) {\n#   hbal.out &lt;- hbal::hbal(Y = Y, Treat = treat, X = covar,  data = data, expand.degree = 2, # cv = TRUE)\n#   out &lt;- hbal::att(hbal.out, dr = FALSE)[1, c(1, 2, 5, 6)]\n#   return(out)\n# }\n\n\n# AIPW\naipw &lt;- function(data, Y, treat, covar) {\n  #library(\"grf\")\n  for (var in c(Y, treat, covar)) {\n    data[, var] &lt;- as.vector(data[, var])\n  }\n  c.forest &lt;- causal_forest(X = data[, covar, drop = FALSE], Y = data[, Y],\n                            W = data[, treat], seed = 1234)\n  att &lt;- average_treatment_effect(c.forest, target.sample = \"treated\", method = \"AIPW\")\n  att &lt;- c(att, att[1] - 1.96 * att[2], att[1] + 1.96 * att[2])\n  return(att)\n}\n\naipw.match &lt;- function(data, Y, treat, covar) {\n  # match on ps\n  ps &lt;- probability_forest(X = data[, covar], Y = as.factor(data[, treat]), seed = 1234)$predictions[,2]\n  m.out &lt;- Match(Y = data[, Y], Tr = data[, treat], X = ps,\n                 estimand = \"ATT\", M = 1, replace = FALSE, ties = FALSE, BiasAdjust = FALSE)\n  mb &lt;- quiet(MatchBalance(treat ~ ps, data = data, match.out = m.out, nboots= 0))\n  ks &lt;- mb$AfterMatching[[1]]$ks$ks$statistic\n  s &lt;- data[c(m.out$index.treated, m.out$index.control), ]\n  out &lt;- aipw(s, Y, treat, covar)\n  #return(out)\n  return(c(out, ks))\n}\n\n### This script checks for robustness by estimating original model\n### using double/debiased machine learning using DoubleML package\ndml &lt;-function(data, Y = NULL, treat = NULL, covar = NULL, clust_var = NULL, ml_l = lrn(\"regr.lm\"), ml_m = lrn(\"regr.lm\")){\n\n  if(is.null(covar)){\n    stop(\"No controls in specification.\")\n  }\n\n  #require(DoubleML)\n  #require(mlr3learners)\n  #require(fixest)\n  #require(ggplot2)\n\n  if(is.null(clust_var) == TRUE){\n\n    dat = data[,c(Y,treat,covar)]\n    dat = na.omit(dat)\n\n    dml_dat = DoubleMLData$new(dat,\n                               y_col = Y,\n                               d_cols = treat,\n                               use_other_treat_as_covariate = FALSE,\n                               x_cols = covar)\n\n  }else{\n\n    dat = data[,c(Y, treat, covar, clust_var)]\n    dat[,clust_var] = as.numeric(factor(dat[,clust_var]))\n    dat = dat[is.na(dat[,Y]) == FALSE,]\n    dat = dat[is.na(dat[,D]) == FALSE,]\n    features = data.frame(model.matrix(formula(paste(c('~ 1',treat,covar), collapse=\"+\")), dat))\n    dat = cbind(dat[,c(Y,clust_var)],features)\n\n    dml_dat = DoubleMLClusterData$new(dat,\n                                      y_col = Y,\n                                      d_cols = treat,\n                                      cluster_cols = clust_var,\n                                      use_other_treat_as_covariate = FALSE,\n                                      x_cols = covar)\n  }\n\n  # Set active treatment treatment\n  dml_dat$set_data_model(treat)\n\n  # Estimate with DML\n  set.seed(pi)\n  dml_mod = DoubleMLPLR$new(dml_dat, ml_l=ml_l, ml_m=ml_m)\n  quiet(dml_mod$fit())\n  out = c(dml_mod$coef[treat], dml_mod$se[treat], dml_mod$confint()[treat,])\n\n  return(out)\n\n}\n\n# execute all estimators\n## estimate all\nestimate_all &lt;- function(data, Y, treat, covar, \n    methods = c(\"diff\", \"reg\", \"om.reg\", \"om.grf\",\n      \"matching\", \"psm\", \"ipw\", \"cbps\", \"ebal\", \n      \"dml\", \"aipw_grf\")) {\n  \n  results &lt;- as.data.frame(matrix(NA, length(methods), 4))\n  rownames(results) &lt;- methods\n  colnames(results) &lt;- c(\"Estimate\", \"SE\", \"CI_lower\", \"CI_upper\")\n  m &lt;- 1\n  if (\"diff\" %in% methods) {\n    results[m, ] &lt;- diff(data, Y, treat) \n    m &lt;- m + 1\n  }\n  if (\"reg\" %in% methods) {\n    results[m, ] &lt;- reg(data, Y, treat, covar) \n    m &lt;- m + 1\n  }\n  if (\"om.reg\" %in% methods) {\n    results[m, ] &lt;- om.reg(data, Y, treat, covar) \n    m &lt;- m + 1\n  }\n  if (\"om.grf\" %in% methods) {\n    results[m, ] &lt;- om.grf(data, Y, treat, covar) \n    m &lt;- m + 1\n  } \n  if (\"matching\" %in% methods) {\n    results[m, ] &lt;- matching(data, Y, treat, covar) \n    m &lt;- m + 1\n  }\n  if (\"psm\" %in% methods) {\n    results[m, ] &lt;- psm(data, Y, treat, covar) \n    m &lt;- m + 1\n  }  \n  if (\"ipw\" %in% methods) {\n    results[m, ] &lt;- ipw(data, Y, treat, covar) \n    m &lt;- m + 1\n  }\n  if (\"cbps\" %in% methods) {\n    results[m, ] &lt;- cbps(data, Y, treat, covar) \n    m &lt;- m + 1\n  }\n  if (\"ebal\" %in% methods) {\n    results[m, ] &lt;- quiet(ebal(data, Y, treat, covar))\n    m &lt;- m + 1\n  }\n  # if (\"hbal\" %in% methods) {\n  #   results[m, ] &lt;- quiet(hbal(data, Y, treat, covar))\n  #   m &lt;- m + 1\n  # }\n  if (\"dml\" %in% methods) {\n    results[m, ] &lt;-dml(data, Y, treat, covar) \n    m &lt;- m + 1\n  }\n  if (\"aipw_grf\" %in% methods) {\n    results[m, ] &lt;- aipw(data, Y, treat, covar) \n    m &lt;- m + 1\n  }\n  return(results)\n}\n\n\n\n1.2.4.1 Function calls\n\n\nquiet: Suppresses output from a function call.\n\ndiff: Difference in means estimator. It runs a linear regression adjusting for robust standard errors and returns the coefficient, standard error, and confidence interval for the treatment variable.\n\nreg: Regression adjustment. Similar to diff but includes additional covariates in the regression model.\n\nmatching: Propensity score matching using the Matching package. It aligns treated units to control units based on covariates and returns the estimated ATT and its confidence interval.\n\npsm: Propensity score matching using a probability forest, followed by matching and estimation of the ATT.\n\nom.reg: Outcome modeling using regression. It predicts the outcome for the treated units based on the model fitted to the control units, and then estimates the ATT.\n\nom.grf: Outcome modeling using generalized random forests, noted as GRF.\n\nipw: Inverse probability weighting,denoted as IPW. It weights observations by the inverse of their estimated propensity scores and calculates the treatment effect with a weighted regression.\n\ncbps: Covariate balancing propensity score, noted as CBPS. It estimates propensity scores to achieve balance on covariates across groups.\n\nebal: Entropy balancing. It reweights the data to balance the covariate distributions.\n\nhbal: Hierarchical balancing. It is an extension of ebal with more complex balancing methods.\n\naipw: Augmented inverse probability weighting, noted as AIPW.\n\naipw.match: Combines matching on propensity scores with AIPW.\n\ndml: Double machine learning. It uses machine learning algorithms to control for confounders when estimating treatment effects.\n\nplot_coef() plots the the ATT estimates, allowing for visual comparison.\n\nCodeplot_coef &lt;- function(out, \n    methods = c(\"diff\", \"reg\", \"om.reg\", \"om.grf\", \n    \"matching\", \"psm\", \"ipw\", \"cbps\", \"ebal\", \n        \"dml\", \"aipw_grf\"),\n    labels = c(\"Diff-in-Means\", \"Reg\", \"OM: Reg\", \"OM: GRF\",\n        \"NN\\nMatching\", \"PS\\nMatching\",\n        \"IPW\", \"CBPS\", \"Ebal\", \"DML\\nElasnet\", \"AIPW-GRF\"),\n    main = NULL,\n    ylab = \"Estimate\",\n    band = NULL,\n    line = NULL,\n    grid = TRUE,\n    main.pos = 1,\n    main.line = -2,\n    ylim = NULL,\n    textsize = 1\n) {\n  \n  if (is.null(methods) == TRUE) {\n    methods &lt;- rownames(out)\n  }\n  \n  if (is.null(labels) == TRUE) {\n    labels &lt;- methods\n  }\n  \n  # # check\n  # if (is.null(out)==FALSE) {\n  #   if (inherits(out, \"ivDiag\") == FALSE) {stop(\"\\\"out\\\" needs to be a \\\"ltz\\\" object.\")}\n  # }\n  # \n  # # title\n  # if (is.null(main)==TRUE) {\n  #   main &lt;- \"Estimates with 95% CIs\"\n  # }\n  \n  \n  # Data for the plot\n  data &lt;- out\n  rg &lt;- range(data[,c(3,4)], na.rm = TRUE)\n  adj &lt;- rg[2] - rg[1]\n  if (is.null(ylim) == TRUE) {\n    ylim  &lt;- c(min(0, rg[1] - 0.3*adj), max(0, rg[2] + 0.35*adj))\n  }\n  adj2 &lt;- ylim[2] - ylim[1] \n  \n  # Set up the plot\n  ncoefs &lt;- length(methods)\n  par(mar = c(2.5, 4, 1, 2))\n  plot(1: ncoefs, data[, 1], xlim = c(0.5, ncoefs + 0.5), ylim = ylim,\n       ylab = \"\", xlab = \"\", main = \"\", \n       axes = FALSE, xaxt = \"n\", yaxt = \"n\", type = \"n\")\n  axis(1, at = 1: ncoefs, labels =  labels, las = 1, cex.axis = 0.8)\n  axis(2, cex.axis = 0.7)\n  mtext(main, main.pos, line = main.line, cex = textsize)\n  mtext(ylab, 2, line = 2.5)\n  if (is.null(band) == FALSE) {\n    rect(-0.5, band[1], ncoefs + 1, band[2], col = \"#ff000030\", border = \"white\") # label at bottom\n  }\n  if (is.null(line) == FALSE) {\n    abline(h = line, col = \"red\", lty = 2)\n  }\n  if (grid == TRUE) {\n    abline(h = axTicks(2), lty = \"dotted\", col = \"gray50\")\n    abline(v = c(0.5, c(1: ncoefs) + 0.5), lty = \"dotted\", col = \"gray50\") # horizontal grid\n  }\n  abline(h = 0, col = \"red\", lwd = 2, lty = \"solid\")\n  segments(y0 = data[, 3], x0 = c(1: ncoefs), y1 = data[, 4], x1 = c(1: ncoefs), lwd = 2) #CI\n  points(1: ncoefs, data[, 1], pch = 16, col = 1, cex = 1.2) #point coefs\n  box()\n}\n\n\n\n\n\n1.2.5 catt() & plot_catt()\n\nThese functions aim to estimate and visualize the Conditional Average Treatment Effect on the Treated (CATT). By using robust standard errors ( se_type = “stata”), we aim to obtain reliable standard errors even in the presence of heteroskedasticity or other violations of the classical linear regression assumptions.\ncatt() estimates the CATT using causal forests.\n\nCodecatt &lt;- function(data, Y, treat, covar){\n  tau.forest &lt;- causal_forest(X = data[, covar], Y = data[, Y],\n                              W = data[, treat], num.trees = 4000)\n  tau0 &lt;- average_treatment_effect(tau.forest,\n                                   target.sample = \"treated\", method = \"AIPW\")\n  tau &lt;- tau.forest$predictions\n  tau.tr &lt;- tau[which(data[, treat]==1)]\n  return(list(catt = tau.tr, att = tau0))\n}\n\n\nplot_catt() plots the CATT density and the ATT estimates, allowing for visual comparison.\n\nCodeplot_catt &lt;- function(catt1, catt2, att1, att2,\n                      xlab = NULL, ylab = NULL, main = NULL, axes.range = NULL,\n                      file = NULL, width = 7, height = 7) {\n\n  if (is.null(axes.range)==TRUE) {\n    axes.range &lt;- range(c(catt1,catt2))\n  }\n  drange &lt;- axes.range[2] - axes.range[1]\n  axes.range &lt;- axes.range + c(-0.1, 0.1) * drange\n  den1 &lt;- density(catt1)\n  den2 &lt;- density(catt2)\n  max.den &lt;- max(c(den1$y, den2$y))\n  adj &lt;- drange * 0.15 / max.den\n  if (!is.null(file)) {\n    pdf(file = file, width = width, height = height)\n    par(mar = c(4, 4, 3, 2))\n  }\n  plot(1, xlim = axes.range, ylim = axes.range, type = \"n\",\n       xlab = xlab, ylab = ylab, main = main)\n  abline(h = 0, v = 0, col = \"gray\", lty = 3)\n  abline(0, 1, col = \"red\", lty = 2)\n  y1 &lt;- adj * den1$y + axes.range[1] - drange*0.03\n  polygon(den1$x,  y1, col=\"#AAAAAA50\", border = NA)\n  lines(den1$x, y1, col = \"gray\", lwd = 1)\n  y2 &lt;- adj * den2$y + axes.range[1] - drange*0.03\n  polygon(y2, den2$x, col=\"#AAAAAA50\", border = NA)\n  lines(y2, den2$x, col = \"gray\", lwd = 1)\n  points(catt1, catt2, cex = 0.5, col = \"#AAAAAA80\", pch = 16)\n  points(catt1, catt2, cex = 0.5, col = \"#777777\", pch = 1, lwd = 0.5)\n  if (is.null(att1) == FALSE) {\n    points(att1, att2, cex = 2, col = 2, pch = 3, lwd = 2)\n  }\n  box()\n  if (!is.null(file)) {graphics.off()}\n}\n\n\n\n1.2.5.1 Function calls\n\n\ncausal_forest: The catt function begins by training a causal forest model using the causal_forest function from the grf package.\n\naverage_treatment_effect: After the causal forest is trained, the function estimates ATT using the doubly-robust AIPW method.\n\n\n\n\n1.2.6 est_qte() & plot_qte()\n\n\n\nest_qte() function estimates the Quantile Treatment Effect on the Treated (QTET) using doubly robust methods. This effect is the difference in a particular quantile of the outcome distribution between the treated and untreated units.\n\n\nCodeest_qte &lt;- function(Y, treat, covar, data, ps = TRUE,\n                    probs = seq(0.05,0.95,0.05), cores = 20,\n                    ylim = NULL) {\n  # Set up\n  if (is.null(covar)) {\n    formla &lt;- as.formula(paste(Y, \"~\", treat))\n  } else {\n    formla &lt;- as.formula(paste(Y, \"~\", treat, \"+\", paste(covar, collapse = \"+\")))\n  }\n  if (is.null(covar) | ps == FALSE) {\n    mod &lt;- ci.qtet(formla, xformla = NULL, data = data,\n                   probs = probs, se = TRUE, iters = 1000, pl = TRUE, cores = cores)\n  } else {\n    xformla &lt;- as.formula(paste(\"~\", paste(covar, collapse = \"+\")))\n    mod &lt;- ci.qtet(formla, xformla = xformla, data = data,\n                   probs = probs, se = TRUE, iters = 1000, pl = TRUE, cores = cores)\n  }\n  return(mod)\n}\n\n\n\n\nplot_qte() function visualizes the QTET estimates.\n\n\nCodeplot_qte &lt;- function(mod, mod2 = NULL, bm = NULL, main= \"\", ylim = NULL,\n                     col = NULL) {\n  # ylim\n  if (is.null(ylim)) {\n    ylim &lt;- range(c(mod$qte.lower, mod$qte.upper))\n  }\n  # Plot\n  par(mar = c(3, 3, 1, 1))\n  plot(1, type = \"n\", xlab = \"\", ylab = \"\",\n       xlim = c(0, 1), ylim = ylim, axes = FALSE)\n  box(); axis(1, at = seq(0.1, 0.9, 0.2)); axis(2)\n  mtext(\"QTET\", 2, line = 2)\n  mtext(\"Quantile\", 1, line = 2)\n  abline(h = 0, lty = 1, lwd = 2, col = \"gray\")\n  title(main, line = -1.5)\n  # model 2\n  if (is.null(mod2) == FALSE) {\n    polygon(c(mod2$probs, rev(mod2$probs)), c(mod2$qte.lower, rev(mod2$qte.upper)),\n            col = \"#FC94AF50\", border = NA)\n  }\n  # benchmark\n  if (is.null(bm) == FALSE) {\n    polygon(c(bm$probs, rev(bm$probs)), c(bm$qte.lower, rev(bm$qte.upper)),\n            col = \"#ADD8E680\", border = NA)\n  }\n  # main\n  if (is.null(col) == TRUE) {\n    col1 &lt;- \"gray30\"\n      col2 &lt;- \"#AAAAAA90\"\n  } else {\n    col1 &lt;- col[1]\n    col2 &lt;- col[2]\n  }\n  polygon(c(mod$probs, rev(mod$probs)), c(mod$qte.lower, rev(mod$qte.upper)),\n          col = col2, border = NA)\n  if (is.null(mod2) == FALSE) {\n    lines(mod2$probs, mod2$qte, col = \"#DC143C80\", lwd = 2)\n    points(mod2$probs, mod2$qte, col = \"#DC143C\", pch = 17, cex = 0.8)\n  }\n  if (is.null(bm) == FALSE) {\n    lines(bm$probs, bm$qte, col = 4, lwd = 2)\n    points(bm$probs, bm$qte, col = 4, pch = 16)\n  }\n  lines(mod$probs, mod$qte, col = col1, lwd = 2)\n  lines(mod$probs, mod$qte.lower, col = col1, lty = 3, lwd = 1.5)\n  lines(mod$probs, mod$qte.upper, col = col1, lty = 3, lwd = 1.5)\n  points(mod$probs, mod$qte, col = col1, pch = 16)\n}\n\n\nArguments\n\n\nps: A boolean argument; if set to TRUE, propensity scores are used in the estimation.\n\nprobs: A sequence of probabilities for which the quantile treatment effects are estimated.\n\ncores: Number of cores to use for parallel computation, which speeds up the process.\n\nmod, mod2, bm: Within the function for QTET estimation, the mod parameter is mandatory, whereas mod2 and bm are optional and may be included for comparative analysis.\n\n\n\n\n1.2.7 sens_ana()\n\nsens_ana() function conducts sensitivity analysis on an estimated treatment effect to assess how susceptible the findings are to potential unobserved confounding.\n\nCodesens_ana &lt;- function(data, Y, treat, covar, bm = NULL, kd = 1)\n{\n  p.forest &lt;- probability_forest(X = data[, covar],\n                                 Y = as.factor(data[, treat]), seed = 1234, num.trees = 4000)\n  data$ps_sens &lt;- p.forest$predictions[,2]\n  data &lt;- subset(data, ps_sens &gt; 0.1 & ps_sens &lt; 0.9)\n  fml &lt;- as.formula(paste(Y, \"~\", treat, \"+\", paste(covar, collapse = \"+\")))\n  mod &lt;- lm(fml, data = data)\n  sens &lt;- sensemakr(model = mod, treatment = treat, benchmark_covariates = bm, kd = kd, sensitivity.of = \"t-value\")\n  plot(sens)\n}\n\n\n\n1.2.7.1 Function calls\n\n\nprobability_forest: The probability forest is trained on the covariates to estimate the propensity score using the probability of each unit receiving the treatment given the observed covariates.\n\nsensemakr: The function from the sensemakr package utilizes sensitivity analysis on the linear model with the treatment variable, optional benchmark covariates, and a kd multiplier that specifies the range of the sensitivity analysis in terms of the proportion of the treatment effect that is due to the omitted variable.\n\n\n\n\n\n\n\nNote\n\n\n\nTo use the above functions, we provide an additional R script. You can source the script and apply these functions. However, this is NOT the official replication file, so please review it carefully before use.\n\n\n\n\n\n\nCalónico, Sebastian, and Jeffrey Smith. 2017. “The Women of the National Supported Work Demonstration.” Journal of Labor Economics 35 (S1): S65–97.\n\n\nDehejia, Rajeev H, and Sadek Wahba. 1999. “Causal Effects in Nonexperimental Studies: Reevaluating the Evaluation of Training Programs.” Journal of the American Statistical Association 94 (448): 1053–62.\n\n\n———. 2002. “Propensity Score-Matching Methods for Nonexperimental Causal Studies.” Review of Economics and Statistics 84 (1): 151–61.\n\n\nFirpo, Sergio. 2007. “Efficient Semiparametric Estimation of Quantile Treatment Effects.” Econometrica 75 (1): 259–76.\n\n\nImbens, Guido W, Donald B Rubin, and Bruce I Sacerdote. 2001. “Estimating the Effect of Unearned Income on Labor Earnings, Savings, and Consumption: Evidence from a Survey of Lottery Players.” American Economic Review, 778–94.\n\n\nLaLonde, Robert J. 1986. “Evaluating the Econometric Evaluations of Training Programs with Experimental Data.” The American Economic Review, 604–20."
  },
  {
    "objectID": "02-LDW.html#assessing-overlap",
    "href": "02-LDW.html#assessing-overlap",
    "title": "\n2  LaLonde-Dehejia-Wahba (LDW) Data\n",
    "section": "\n2.1 Assessing Overlap",
    "text": "2.1 Assessing Overlap\nTo identify the average causal effect under unconfoundedness, we need to ensure that we can estimate the average effect at every value for the covariates. Thus, we require overlaps between the treated and control units. Using the assess_overlap() function, we can assess overlaps in propensity scores. To test the overlap assumption, we plot histograms using the log-odds of propensity scores, i.e., \\(\\log(\\frac{\\hat{e}}{1-\\hat{e}})\\).\nIdeally, for a well-balanced experimental design, the distributions of the treated (red) and the control (gray) groups should overlap.\n\n2.1.1 LDW-Experimental\n\nCodeldw_ps &lt;- assess_overlap(data = ldw, treat = treat, cov = covar)\n#&gt; -1.2254 0.7533904\n\n\n\nFIGURE1. SubfigureA:LDW-Experimental.\n\n\n\n\n2.1.2 LDW-CPS1 and LDW-PSID1\n\nCodepar(mfrow = c(1,2))\nldw_cps_ps &lt;- assess_overlap(data = ldw_cps, treat = treat, cov = covar)\n#&gt; -16.1181 1.787226\nldw_psid_ps &lt;- assess_overlap(data = ldw_psid, treat = treat, cov = covar)\n#&gt; -16.1181 3.824234\n\n\n\nFIGURE1. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1.\n\n\n\n\n2.1.3 Overlap in Original LDW Samples\nAs expected, LDW-Experimental shows a almost perfect overlap. However, both observational samples show very poor overlaps. Most notably, the propensity scores of many treated units do not lie within the support of the controls’ propensity scores, and a substantial proportion of the control units possess extremely low log-odds."
  },
  {
    "objectID": "02-LDW.html#trimming-to-improve-overlap",
    "href": "02-LDW.html#trimming-to-improve-overlap",
    "title": "\n2  LaLonde-Dehejia-Wahba (LDW) Data\n",
    "section": "\n2.2 Trimming to Improve Overlap",
    "text": "2.2 Trimming to Improve Overlap\nBased on LDW-CPS1 and LDW-PSID1, we further construct two trimmed samples to improve overlap. Trimming involves two steps.\nFirst, we merge the experimental controls from LDW-Experimental into LDW-CPS1 (or LDW-PSID1) to enhance the control group with more units. Then, we can estimate each unit’s propensity included in the experiment using GRF. The purpose of trimming is to remove units that are too dissimilar from the other group to ensure a better balance between the treated and control groups. We can use trim() to trim the data.\n\nFor LDW-CPS1, the threshold is set at 0.9, meaning any unit with a propensity score higher than 0.9 will be excluded.\nFor LDW-PSID1, the threshold is lower, at 0.8, indicating a stricter criterion for inclusion in the analysis.\n\n\nCode# re-estimate each unit’s propensity by merged data\nldw_cps_ps &lt;- assess_overlap(data = ldw_cps.plus, treat = treat, cov = covar)\n#&gt; -16.1181 3.542706\nldw_psid_ps &lt;- assess_overlap(data = ldw_psid.plus, treat = treat, cov = covar)\n#&gt; -16.1181 7.102692\n\ntrim &lt;- function(data, ps = \"ps_assoverlap\", threshold = 0.9) {\n  sub &lt;- data[which(data[, ps] &lt; threshold), ]\n  return(sub)\n}\n\nldw_cps_trim &lt;- trim(ldw_cps_ps, threshold = 0.9)\nldw_psid_trim &lt;- trim(ldw_psid_ps, threshold = 0.8)\n\n\nSecond, using the trimmed data and the same set of covariates, we reestimate propensity scores with GRF; this time, experimental controls are excluded.\n\nCode# cps data\n# excluding the experimental controls\nldw_cps_trim_match &lt;- subset(ldw_cps_trim, sample %in% c(1,3) & ps_assoverlap)\n# re-estimate propensity scores and employ 1:1 matching\nldw_cps_trim_match &lt;- psmatch(data = ldw_cps_trim_match, Y = \"re78\", treat = \"treat\", cov = covar)\n\n# psid data\n# excluding the experimental controls\nldw_psid_trim_match &lt;- subset(ldw_psid_trim, sample %in% c(1,4) & ps_assoverlap)\n# re-estimate propensity scores and employ 1:1 matching\nldw_psid_trim_match &lt;- psmatch(data = ldw_psid_trim_match, Y = \"re78\", treat = \"treat\", cov = covar)\n\n\nWe then employ a 1:1 matching based on the reestimated propensity scores to further trim the nonexperimental controls.\n\nCode# We conduct this procedure to trim all samples simultaneously to improve overlap in the final samples.\n\n#cps\nldw_trim_cps &lt;- subset(ldw_cps_trim, sample %in% c(1,2) & ps_assoverlap &lt;= 0.9)\nldw_trim_cps$treat[which(ldw_trim_cps$sample == 2)] &lt;- 0\n#psid\nldw_trim_psid &lt;- subset(ldw_psid_trim, sample %in% c(1,2) & ps_assoverlap &lt;= 0.8)\nldw_trim_psid$treat[which(ldw_trim_psid$sample == 2)] &lt;- 0"
  },
  {
    "objectID": "02-LDW.html#reassessing-overlap",
    "href": "02-LDW.html#reassessing-overlap",
    "title": "\n2  LaLonde-Dehejia-Wahba (LDW) Data\n",
    "section": "\n2.3 Reassessing Overlap",
    "text": "2.3 Reassessing Overlap\n\n\n\n\n\n\nTip\n\n\n\nAs shown in the following figures, overlap improves significantly in both samples post-trimming, though this comes with the cost of reduced sample sizes.\n\n\n\nCodepar(mfrow = c(1,2))\n# cps data\nldw_cps_trim_match_ps &lt;- assess_overlap(data = ldw_cps_trim_match, treat = treat, cov = covar, xlim = c(-3,3))\n\n# psid data\nldw_psid_trim_match_ps &lt;- assess_overlap(data = ldw_psid_trim_match, treat = treat, cov = covar, xlim = c(-3,3))\n\n\n\nFIGURE1. SubfigureD:TrimmedLDW-CPS1. SubfigureE:TrimmedLDW-PSID1."
  },
  {
    "objectID": "02-LDW.html#checking-covariate-balance",
    "href": "02-LDW.html#checking-covariate-balance",
    "title": "\n2  LaLonde-Dehejia-Wahba (LDW) Data\n",
    "section": "\n2.4 Checking Covariate Balance",
    "text": "2.4 Checking Covariate Balance\nWe can also check covariate balance directly by love.plot(). As shown in the following figures, covariate overlap improves significantly in both samples post-trimming (matching).\n\nCode# cps data\nlove.plot(ldw_cps, ldw_cps_trim_match, treat = treat, covar = covar, title = \"Covariate Balance of LDW-CPS1\")\n\n# psid data\nlove.plot(ldw_psid, ldw_psid_trim_match, treat = treat, covar = covar, title = \"Covariate Balance of LDW-PSID1\")"
  },
  {
    "objectID": "02-LDW.html#estimating-the-att",
    "href": "02-LDW.html#estimating-the-att",
    "title": "\n2  LaLonde-Dehejia-Wahba (LDW) Data\n",
    "section": "\n2.5 Estimating the ATT",
    "text": "2.5 Estimating the ATT\nNext, we estimate the ATT using both the original LDW observational samples and the newly constructed trimmed samples. We apply a variety of estimators, including simple difference-in-means, regression, the OaxacaBlinderestimator, GRF as an outcome model, 1: 5 nearest neighbor matching with bias correction, IPW with propensity scores estimated by GRF, covariate balancing propensity score (CBPS), entropy balancing, double/debiased matching learning using elastic net, and AIPW implemented via GRF. All estimators use the same set of ten covariates as before.\nTo achieve such a comprehensive analysis of the ATT, we can use the estimate_all() and plot_coef() function.\n\nCodeload(\"data/trimmed.RData\")\n\n# experimental\nout1 &lt;- estimate_all(data = ldw, Y = \"re78\", treat = \"treat\", cov = covar)\nout2 &lt;- estimate_all(ldw_trim_cps, \"re78\", \"treat\", covar)\nout3 &lt;- estimate_all(ldw_trim_psid, \"re78\", \"treat\", covar)\n# nonexperimental\nout4 &lt;- estimate_all(ldw_cps, \"re78\", \"treat\", covar)\nout5 &lt;- estimate_all(ldw_psid, \"re78\", \"treat\", covar)\nout6 &lt;- estimate_all(ldw_cps_trim, \"re78\", \"treat\", covar)\nout7 &lt;- estimate_all(ldw_psid_trim, \"re78\", \"treat\", covar)\n\n\n\nCodepar(mfrow = c(4,1))\nband &lt;- out1[1, 3:4]\nest &lt;- out1[1, 1]\nplot_coef(out4, band = band, line = est, ylim = c(-15500, 5500), main = \"(A) LDW-CPS1\")\n\nband &lt;- out1[1, 3:4]\nest &lt;- out1[1, 1]\nplot_coef(out5, band = band, line = est, ylim = c(-15500, 5500), main = \"(B) LDW-PSID1\")\n\nband &lt;- out2[1, 3:4]\nest &lt;- out2[1, 1]\nplot_coef(out6, band = band, line = est, ylim = c(-15500, 5500), main = \"(C) Trimmed LDW-CPS1\")\n\nband &lt;- out3[1, 3:4]\nest &lt;- out3[1, 1]\nplot_coef(out7, band = band, line = est, ylim = c(-15500, 5500), main = \"(D) Trimmed LDW-PSID1\")\n\n\n\nFIGURE 3. ATT Estimates Given Unconfoundedness: LDW Samples\n\n\n\nThe above figures show the ATT estimates and their 95% confidence intervals using four different samples: LDW-CPS1, LDW-PSID1, Trimmed LDW-CPS1, and Trimmed LDW-PSID1.\nAs shown in Figure 3(A), when using LDW-CPS1, all estimators, except difference in-means, produce positive estimates, although there are noticeable variations among them. Nearest neighbor matching outperforms other estimators, aligning closely with the experimental benchmark of $1,794. Notably, CBPS, entropy balancing, and AIPW-GRF also produce results close to the benchmark. Despite numerical differences, these estimates, except for difference-in-means, cannot be statistically distinguished from one another. Figure 3(B) shows that estimates based on LDW-PSID1 exhibit greater variations. Setting aside the difference-in-means, the estimates span from $4 to $2,420. Among them, the AIPW-GRF estimator produces an estimate closest to the experimental benchmark.\nFigure 3(C) and (D) show that by using trimmed data with improved overlap, estimates produced by various estimators are substantially more stable.\nThe ATT results are presented in the table below:\n\nCode# print the result\na &lt;- list(out4, out5, out6, out7)\nn &lt;- nrow(out1)\nsav &lt;- matrix(\"\", n+1, length(a)*3-1)\nfor (j in 1:length(a)) {\n    out &lt;- a[[j]]\n    n &lt;- nrow(out)\n    for (i in 2:(nrow(out)+1)) {\n        sav[i, j*3-2] &lt;- sprintf(\"%.2f\", out[i-1, 1])\n        sav[i, j*3-1] &lt;- paste0(\"(\", sprintf(\"%.2f\", out[i-1, 2]), \")\")\n    }\n}\nsav[1, 1] &lt;- sprintf(\"%.2f\", out1[1, 1])\nsav[1, 2] &lt;- paste0(\"(\", sprintf(\"%.2f\", out1[1, 2]), \")\")\nsav[1, 4] &lt;- sprintf(\"%.2f\", out1[1, 1])\nsav[1, 5] &lt;- paste0(\"(\", sprintf(\"%.2f\", out1[1, 2]), \")\")\nsav[1, 7] &lt;- sprintf(\"%.2f\", out2[1, 1])\nsav[1, 8] &lt;- paste0(\"(\", sprintf(\"%.2f\", out2[1, 2]), \")\")\nsav[1, 10] &lt;- sprintf(\"%.2f\", out3[1, 1])\nsav[1, 11] &lt;- paste0(\"(\", sprintf(\"%.2f\", out3[1, 2]), \")\")\ncolnames(sav) &lt;- c(\"LDW-CPS1\", \"\", \"\", \"LDW-PSID1\", \"\", \"\", \"LDW-CPS1 (PS Trimmed) \", \"\", \"\", \"LDW-PSID1 (PS Trimmed)\", \"\")\nrownames(sav) &lt;- c(\"Experimental Benchmark\", \"Difference-in-Means\", \"Regression\", \" Oaxaca Blinder\", \"GRF\", \"NN Matching\", \"PS Matching\", \"IPW\", \"CBPS\", \"Entropy Balancing\", \"DML-ElasticNet\", \"AIPW-GRF\")\nsav %&gt;% knitr::kable(booktabs=TRUE, caption = \" Table B1 in the Supplementary Materials (SM)\")\n\n\nTable B1 in the Supplementary Materials (SM)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLDW-CPS1\n\n\nLDW-PSID1\n\n\nLDW-CPS1 (PS Trimmed)\n\n\nLDW-PSID1 (PS Trimmed)\n\n\n\n\nExperimental Benchmark\n1794.34\n(670.82)\n\n1794.34\n(670.82)\n\n1911.04\n(737.71)\n\n306.29\n(985.98)\n\n\nDifference-in-Means\n-8497.52\n(581.92)\n\n-15204.78\n(655.91)\n\n1483.82\n(824.44)\n\n-1505.24\n(1219.89)\n\n\nRegression\n1066.38\n(626.85)\n\n4.16\n(854.15)\n\n1751.16\n(824.20)\n\n-1939.59\n(1154.45)\n\n\nOaxaca Blinder\n1133.28\n(624.26)\n\n687.82\n(635.26)\n\n1507.48\n(672.08)\n\n-1511.20\n(900.46)\n\n\nGRF\n1078.83\n(629.88)\n\n766.29\n(635.04)\n\n1442.19\n(665.76)\n\n-1401.32\n(792.83)\n\n\nNN Matching\n1729.12\n(815.38)\n\n2255.47\n(1403.83)\n\n2137.90\n(946.11)\n\n-1564.93\n(1209.89)\n\n\nPS Matching\n1360.89\n(748.71)\n\n2275.83\n(762.42)\n\n1341.73\n(802.29)\n\n-2746.63\n(1275.32)\n\n\nIPW\n1236.84\n(687.14)\n\n739.34\n(893.32)\n\n1343.01\n(826.44)\n\n-2117.63\n(1270.02)\n\n\nCBPS\n1408.01\n(654.96)\n\n2437.70\n(877.80)\n\n1471.35\n(813.29)\n\n-1885.28\n(1369.64)\n\n\nEntropy Balancing\n1406.27\n(654.93)\n\n2420.49\n(876.85)\n\n1472.12\n(812.92)\n\n-1776.73\n(1551.89)\n\n\nDML-ElasticNet\n1068.62\n(627.81)\n\n91.01\n(861.30)\n\n1912.25\n(818.40)\n\n-2112.57\n(1125.17)\n\n\nAIPW-GRF\n1571.17\n(703.86)\n\n1422.82\n(772.78)\n\n1426.58\n(815.99)\n\n-1830.25\n(1169.91)\n\n\n\n\n\nColumns 1 and 2 report the estimates from LDW-CPS1 and LDW-PSID1, respectively, while columns 3 and 4 report the estimates from the trimmed samples with improved overlap. Robust standard errors are in the parentheses. Improved overlap in trimmed samples generally leads to estimates with higher consistency with the benchmark. The trimmed samples often show increased standard errors, which is expected as trimming reduces the sample size, thus increasing variance.\nAs shown in column 1, when using LDW-CPS1, all estimators, except difference-in-means, produce estimates exceeding $1,000, although there are noticeable variations among them. Nearest neighbor matching outperforms other estimators, aligning closely with the experimental benchmark of $1,794. Notably, propensity score matching, entropy balancing, and AIPW-GRF also produce results close to the benchmark. The standard errors of these estimates are large. As a result, despite numerical differences, these estimates, except for difference-in-means, cannot be statistically distinguished from one another. Column 2 shows that estimates based on LDW-PSID1 exhibit greater variations.\n\n\n\n\n\n\nTip\n\n\n\nThese findings suggest that while improved overlap based on observed covariates can reduce model dependency and estimate variability across different estimators, it does not guarantee consistency without validating unconfoundedness."
  },
  {
    "objectID": "02-LDW.html#alternative-estimands-catt-and-qtet",
    "href": "02-LDW.html#alternative-estimands-catt-and-qtet",
    "title": "\n2  LaLonde-Dehejia-Wahba (LDW) Data\n",
    "section": "\n2.6 Alternative Estimands: CATT and QTET",
    "text": "2.6 Alternative Estimands: CATT and QTET\n\n2.6.1 Conditional Average Treatment Effect on the Treated (CATT)\nExploring causal estimates for alternative estimands, such as heterogeneous treatment effects and quantile treatment effects, can help assess unconfoundedness.\nCATT can reveal how the treatment effect varies across different subgroups defined by covariates. Using both the original LDW data and the trimmed versions, we estimate the CATT using a causal forest through AIPW-GRF. We can use the wrapper function catt() to estimate CATT.\n\nCode# estimate catt\ncatt.ldw &lt;- catt(ldw, Y, treat, covar)\ncatt.cps &lt;- catt(ldw_cps, Y, treat, covar)\ncatt.psid &lt;- catt(ldw_psid, Y, treat, covar)\ncatt.cps.trim &lt;- catt(ldw_cps_trim, Y, treat, covar)\ncatt.psid.trim &lt;- catt(ldw_psid_trim, Y, treat, covar)\n# trimmed experimental data\ncatt.ldw.cps &lt;- catt(ldw_trim_cps, Y, treat, covar)\ncatt.ldw.psid &lt;- catt(ldw_trim_psid, Y, treat, covar)\n\n\nThen, we can use plot_catt() to visualize the result. In the following figures, we plot the estimated CATT from observational data at the covariate values of each treated unit against their corresponding experimental benchmarks. The gray dot represents a pair of CATT estimates, while the red cross depicts the pair of estimated ATTs.\n\nCodepar(mfrow = c(2,2))\n# plot catt - \"CATT (Experimental)\" and \"CATT (CPS-Full)\"\ncatt1 &lt;- catt.ldw$catt\natt1 &lt;- catt.ldw$att[1]\ncatt2 &lt;- catt.cps$catt\natt2 &lt;- catt.cps$att[1]\nplot_catt(catt1, catt2, att1, att2, \"CATT (Experimental)\", \"CATT (CPS-Full)\",\n          main = \"\", c(-8000, 8000))\n\n# plot catt - \"CATT (Experimental)\" and \"CATT (PSID-Full)\"\ncatt1 &lt;- catt.ldw$catt\natt1 &lt;- catt.ldw$att[1]\ncatt2 &lt;- catt.psid$catt\natt2 &lt;- catt.psid$att[1]\nplot_catt(catt1, catt2, att1, att2, \"CATT (Experimental)\", \"CATT (PSID-Full)\",\n    main = \"\", c(-8000, 8000))\n\n# plot catt - \"CATT (Experimental)\" and \"CATT (CPS-Trimmed)\"\ncatt1 &lt;- catt.ldw.cps$catt\natt1 &lt;- catt.ldw.cps$att[1]\ncatt2 &lt;- catt.cps.trim$catt\natt2 &lt;- catt.cps.trim$att[1]\nplot_catt(catt1, catt2, att1, att2, \"CATT (Experimental)\", \"CATT (CPS-Trimmed)\",\n    main = \"\", c(-8000, 8000))\n\n# plot catt - \"CATT (Experimental)\" and \"CATT (PSID-Trimmed)\"\ncatt1 &lt;- catt.ldw.psid$catt\natt1 &lt;- catt.ldw.psid$att[1]\ncatt2 &lt;- catt.psid.trim$catt\natt2 &lt;- catt.psid.trim$att[1]\nplot_catt(catt1, catt2, att1, att2, \"CATT (Experimental)\", \"CATT (PSID-Trimmed)\",\n    main = \"\", c(-8000, 8000))\n\n\n\nFIGURE 4. CATT Estimates using LDW Data: Experimental vs. Nonexperimental\n\n\n\nAlthough the AIPW estimator can produce ATT estimates closely aligned with the experimental benchmark using LDW data, its performance for revealing the true CATT is considerably worse. Specifically, with LDW-CPS1, CATT estimates span from $-5,456.1 to $6,997.1, contrasting with the CATT estimated from experimental data which ranges from $-345.3 to $4,148.5. It overestimates CATT that exceeds the ATT and underestimates CATT that falls below the ATT. Employing LDW-PSID generates CATT estimates ranging from $-8131.2 to $4381.0. With trimmed LDW-CPS, the CATT estimates align more closely with those from the experimental data. However, using trimmed LDW-PSID, the majority of CATT estimates are negative, suggesting significant biases.\n\n2.6.2 Quantile Treatment Effect on the Treated (QTET)\nQTET is less sensitive to outliers and can uncover the heterogeneity in treatment effects that may be obscured by average treatment effect estimates. Our calculation of the QTET uses the propensity score re-weighting approach proposed by Firpo (2007).\nTo proceed, we can use the wrapper function qte().\n\nCode# estimate qte (some of the following lines are not run due to computational limitation)\n\n## experimental\nqte.ldw &lt;- est_qte(Y, treat, NULL, data = ldw)\nqte.ldw.cps &lt;- est_qte(Y, treat, NULL, data = ldw_trim_cps)\nqte.ldw.psid &lt;- est_qte(Y, treat, NULL, data = ldw_trim_psid)\n\n## non-experimental\n#qte.ldw_cps &lt;- est_qte(Y, treat, covar, data = ldw_cps) # adjusted\n#qte.ldw_cps0 &lt;- est_qte(Y, treat, NULL, data = ldw_cps) # unadjusted\nqte.ldw_cps.trim &lt;- est_qte(Y, treat, covar, data = ldw_cps_trim) # adjusted\nqte.ldw_cps.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_cps_trim) # unadjusted\n#qte.ldw_psid &lt;- est_qte(Y, treat, covar, data = ldw_psid) # adjusted\n#qte.ldw_psid0 &lt;- est_qte(Y, treat, NULL, data = ldw_psid) # unadjusted\nqte.ldw_psid.trim &lt;- est_qte(Y, treat, covar, data = ldw_psid_trim) # adjusted\nqte.ldw_psid.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_psid_trim) # unadjusted\n\n\nWe can use plot_qte() to plot the result and compare the treatment effects estimated both before and after trimming based on propensity scores.\nFor each dataset, there are three lines representing:\n\nExperimental (blue line with diamond markers): QTET estimates based on experimental data, which serve as a benchmark.\nUnadjusted (pink line with triangle markers): QTET estimates from the observational data without any adjustments.\nAdjusted (black line with circle markers): QTET estimates from the observational data after adjusting for covariates.\n\n\nCode# plot qte\n\n#load the data\nload(\"data/qte_ldw.rds\")\n\npar(mfrow = c(2,2))\n# CPS\nplot_qte(qte.ldw_cps, qte.ldw_cps0, qte.ldw, main = \"LDW-CPS\", ylim = c(-25000, 15000))\nlegend(\"bottomleft\", legend = c(\"Experimental\", \"Unadjusted\", \"Adjusted\"), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = \"n\")\n\n## CPS trimmed\nplot_qte(qte.ldw_cps.trim, qte.ldw_cps.trim0, qte.ldw.cps, main = \"LDW-CPS (Trimmed)\", ylim = c(-25000, 15000))\nlegend(\"bottomleft\", legend = c(\"Experimental\", \"Unadjusted\", \"Adjusted\"), \n    lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = \"n\")\n\n# PSID\nplot_qte(qte.ldw_psid, qte.ldw_psid0, qte.ldw, main = \"LDW-PSID\", ylim = c(-25000, 15000))\nlegend(\"bottomleft\", legend = c(\"Experimental\", \"Unadjusted\", \"Adjusted\"), \n    lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = \"n\")\n\n# PSID trimmed\nplot_qte(qte.ldw_psid.trim, qte.ldw_psid.trim0, qte.ldw.psid, main = \"LDW-PSID (Trimmed)\", ylim = c(-25000, 15000))\nlegend(\"bottomleft\", legend = c(\"Experimental\", \"Unadjusted\", \"Adjusted\"), \n    lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = \"n\")\n\n\n\nFIGURE 5. Quantile Treatment Effects: Experimental vs. Nonexperimental\n\n\n\nThese figures plot the QTET estimates using both the LDW experimental data and non-experimental data. The QTET estimates from either the original or trimmed LDW-CPS1 data align reasonably well with the true QTET, although they are often underpowered. In contrast, the QTET of the original or trimmed LDW-PSID1 data displays notable biases compared to the experimental benchmark, which is close to zero.\n\n\n\n\n\n\nTip\n\n\n\nThis analysis suggests that, when considering alternative estimands such as CATT and QTET among the four observational samples, only trimmed LDW-CPS1 yields results consistently aligned closely with the experimental benchmark."
  },
  {
    "objectID": "02-LDW.html#validation-through-placebo-analyses",
    "href": "02-LDW.html#validation-through-placebo-analyses",
    "title": "\n2  LaLonde-Dehejia-Wahba (LDW) Data\n",
    "section": "\n2.7 Validation through Placebo Analyses",
    "text": "2.7 Validation through Placebo Analyses\nWe conduct placebo analyses to further assess the plausibility of unconfoundedness. To do so, we select earnings in 1975 (re75) as the placebo outcome and remove both re75 and u75 from the set of conditioning variables. The trimmed samples are based on 1:1 matching of propensity scores estimated via GRF. (Two new trimmed samples are created without using re75 and u75.) Similarly, we can use estimate_all to calculate the ATT for the placebo analysis, conditional on the remaining covariates.\n\nCodeY &lt;- \"re75\"\ntreat &lt;- \"treat\"\ncovar &lt;- c(\"age\", \"education\", \"black\", \"hispanic\", \"married\", \"nodegree\", \"re74\", \"u74\")\n\n# experimental\nout1 &lt;- estimate_all(ldw, Y, \"treat\", covar)\nout2 &lt;- estimate_all(ldw_trim_cps_pl, Y, \"treat\", covar)\nout3 &lt;- estimate_all(ldw_trim_psid_pl, Y, \"treat\", covar)\n# no experimental\nout4 &lt;- estimate_all(ldw_cps, Y, \"treat\", covar)\nout5 &lt;- estimate_all(ldw_psid, Y, \"treat\", covar)\nout6 &lt;- estimate_all(ldw_cps_trim_pl, Y, \"treat\", covar)\nout7 &lt;- estimate_all(ldw_psid_trim_pl, Y, \"treat\", covar)\n\n\n\nCodepar(mfrow = c(4,1))\nband &lt;- out1[1, 3:4]\nest &lt;- out1[1, 1]\nylim &lt;- c(-12000, 2000)\nplot_coef(out4, band = band, line = est, ylim = ylim, main = \"(A) LDW-CPS1\")\n\nband &lt;- out1[1, 3:4]\nest &lt;- out1[1, 1]\nplot_coef(out5, band = band, line = est, ylim = ylim, main = \"(B) LDW-PSID1\")\n\nband &lt;- out2[1, 3:4]\nest &lt;- out2[1, 1]\nplot_coef(out6, band = band, line = est, ylim = ylim, main = \"(C) Trimmed LDW-CPS1\")\n\nband &lt;- out3[1, 3:4]\nest &lt;- out3[1, 1]\nplot_coef(out7, band = band, line = est, ylim = ylim, main = \"(D) Trimmed LDW-PSID1\")\n\n\n\nFIGURE 6. Placebo Test: ’75 Earnings as the Outcome\n\n\n\nFigure 6 presents the findings. Not surprisingly, the experimental benchmarks are near zero and statistically insignificant. However, all estimators using nonexperimental data generate large, negative estimates. Again, with trimmed data, the estimates are stable but remain statistically different from zero.\nThe Placebo ATT results are presented in the table below:\n\nCode# print the result\na &lt;- list(out4, out5, out6, out7)\nn &lt;- nrow(out1)\nsav &lt;- matrix(\"\", n+1, length(a)*3-1)\nfor (j in 1:length(a)) {\n    out &lt;- a[[j]]\n    n &lt;- nrow(out)\n    for (i in 2:(nrow(out)+1)) {\n        sav[i, j*3-2] &lt;- sprintf(\"%.2f\", out[i-1, 1])\n        sav[i, j*3-1] &lt;- paste0(\"(\", sprintf(\"%.2f\", out[i-1, 2]), \")\")\n    }\n}\nsav[1, 1] &lt;- sprintf(\"%.2f\", out1[1, 1])\nsav[1, 2] &lt;- paste0(\"(\", sprintf(\"%.2f\", out1[1, 2]), \")\")\nsav[1, 4] &lt;- sprintf(\"%.2f\", out1[1, 1])\nsav[1, 5] &lt;- paste0(\"(\", sprintf(\"%.2f\", out1[1, 2]), \")\")\nsav[1, 7] &lt;- sprintf(\"%.2f\", out2[1, 1])\nsav[1, 8] &lt;- paste0(\"(\", sprintf(\"%.2f\", out2[1, 2]), \")\")\nsav[1, 10] &lt;- sprintf(\"%.2f\", out3[1, 1])\nsav[1, 11] &lt;- paste0(\"(\", sprintf(\"%.2f\", out3[1, 2]), \")\")\ncolnames(sav) &lt;- c(\"LDW-CPS1\", \"\", \"\", \"LDW-PSID1\", \"\", \"\", \"LDW-CPS1 (PS Trimmed) \", \"\", \"\", \"LDW-PSID1 (PS Trimmed)\", \"\")\nrownames(sav) &lt;- c(\"Experimental Benchmark\", \"Difference-in-Means\", \"Regression\", \" Oaxaca Blinder\", \"GRF\", \"NN Matching\", \"PS Matching\", \"IPW\", \"CBPS\", \"Entropy Balancing\", \"DML-ElasticNet\", \"AIPW-GRF\")\nsav %&gt;% knitr::kable(booktabs=TRUE, caption = \" Table B2 in the Supplementary Materials (SM)\")\n\n\nTable B2 in the Supplementary Materials (SM)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLDW-CPS1\n\n\nLDW-PSID1\n\n\nLDW-CPS1 (PS Trimmed)\n\n\nLDW-PSID1 (PS Trimmed)\n\n\n\n\nExperimental Benchmark\n265.15\n(305.00)\n\n265.15\n(305.00)\n\n273.86\n(334.27)\n\n-210.15\n(693.12)\n\n\nDifference-in-Means\n-12118.75\n(247.18)\n\n-17531.28\n(360.60)\n\n-1456.55\n(484.60)\n\n-4670.77\n(1057.12)\n\n\nRegression\n-1134.82\n(272.44)\n\n-2757.40\n(589.02)\n\n-1256.96\n(329.96)\n\n-3694.56\n(852.84)\n\n\nOaxaca Blinder\n-1096.70\n(395.18)\n\n-2640.76\n(367.46)\n\n-1232.17\n(402.36)\n\n-3528.62\n(827.83)\n\n\nGRF\n-1579.02\n(373.45)\n\n-4334.56\n(343.83)\n\n-1345.15\n(362.39)\n\n-3879.50\n(656.89)\n\n\nNN Matching\n-1465.93\n(351.78)\n\n-1913.65\n(805.37)\n\n-1411.42\n(357.45)\n\n-3790.08\n(929.82)\n\n\nPS Matching\n-1454.83\n(421.13)\n\n-2838.18\n(499.11)\n\n-1424.20\n(464.65)\n\n-5785.12\n(965.43)\n\n\nIPW\n-1568.77\n(337.54)\n\n-3183.02\n(734.24)\n\n-1674.99\n(500.00)\n\n-4199.29\n(1022.62)\n\n\nCBPS\n-1227.83\n(297.89)\n\n-2282.31\n(834.92)\n\n-1231.13\n(468.41)\n\n-3676.24\n(1059.83)\n\n\nEntropy Balancing\n-1228.49\n(297.88)\n\n-2250.80\n(842.15)\n\n-1231.01\n(468.56)\n\n-3551.89\n(1062.82)\n\n\nDML-ElasticNet\n-1152.96\n(271.75)\n\n-2725.28\n(591.57)\n\n-1262.44\n(330.59)\n\n-3779.88\n(830.53)\n\n\nAIPW-GRF\n-1275.34\n(262.33)\n\n-2506.00\n(620.09)\n\n-1370.92\n(370.87)\n\n-3836.34\n(823.57)\n\n\n\n\n\nThe first row of the table shows that the experimental benchmarks are near zero and statistically insignificant. In the placebo analysis, all estimators using observational data generate large, negative estimates.\n\n\n\n\n\n\nTip\n\n\n\nMoreover, almost all the estimators are significantly different from the targeted analysis. Since the placebo estimates are always large and negative while the estimates in the former analysis are smaller in magnitude or positive, this could suggest that the methods are sensitive to the true effect."
  },
  {
    "objectID": "02-LDW.html#sensitivity-analyses",
    "href": "02-LDW.html#sensitivity-analyses",
    "title": "\n2  LaLonde-Dehejia-Wahba (LDW) Data\n",
    "section": "\n2.8 Sensitivity Analyses",
    "text": "2.8 Sensitivity Analyses\nWe also conduct sensitivity analyses using the LDW data, with results depicted in contour plots below. We can use sens_ana to conduct the sensitivity analyses.\n\nCodepar(mfrow = c(1,2))\nY &lt;- \"re78\"\ntreat &lt;- \"treat\"\ncovar &lt;- c(\"age\", \"education\", \"black\", \"hispanic\", \"married\", \"nodegree\", \"re74\", \"re75\", \"u74\", \"u75\")\nbm &lt;- c(\"re75\")\n\n# ldw data\n# sens_ana(ldw, Y, treat, covar, bm)\n\n# trimmed LDW-CPS data\nsens_ana(ldw_cps, Y, treat, covar, bm, kd = 1:3)\n\n# trimmed LDW-PSID data\nsens_ana(ldw_psid, Y, treat, covar, bm)\n\n\n\nFIGURE B3. Sensitivity Analyses for Trimmed LDW-CPS1 and LDW-PSID1\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe analyses suggest that the estimated training effect based on trimmed LDW-CPS is less sensitive to potential confounders compared to trimmed LDW-PSID.\n\n\nFor instance, with trimmed LDW-CPS, the estimate remains positive and large even when a confounder’s correlations with treatment and outcome are triple those of re75, whereas the presence of re75 would lead to a negative estimated effect using trimmed LDW-PSID."
  },
  {
    "objectID": "02-LDW.html#summary",
    "href": "02-LDW.html#summary",
    "title": "\n2  LaLonde-Dehejia-Wahba (LDW) Data\n",
    "section": "\n2.9 Summary",
    "text": "2.9 Summary\nAfter reexamining both the LDW data and the original Lalonde male sample, we offer some new insights into the challenge posed by LaLonde. First, we agree with existing literature that ensuring overlap and using comparable control units are essential for credible causal estimates. Second, while the choice of method is less critical with overlap, as most methods yield similar results, the propensity score remains a vital tool for assessing overlap and is integral to many estimators. Third, we stress the importance of understanding the treatment assignment mechanism and the need for additional tests to validate unconfoundedness. The LDW dataset is somewhat unique in that many methods approximate the experimental benchmark for the average effects under overlap, a success not mirrored with the original LaLonde data. However, even with LDW data, placebo tests fail to substantiate unconfoundedness, and sensitivity analysis reveals the fragility of the regression estimate using LDW-PSID1.\n\n\n\n\nCalónico, Sebastian, and Jeffrey Smith. 2017. “The Women of the National Supported Work Demonstration.” Journal of Labor Economics 35 (S1): S65–97.\n\n\nDehejia, Rajeev H, and Sadek Wahba. 1999. “Causal Effects in Nonexperimental Studies: Reevaluating the Evaluation of Training Programs.” Journal of the American Statistical Association 94 (448): 1053–62.\n\n\n———. 2002. “Propensity Score-Matching Methods for Nonexperimental Causal Studies.” Review of Economics and Statistics 84 (1): 151–61.\n\n\nFirpo, Sergio. 2007. “Efficient Semiparametric Estimation of Quantile Treatment Effects.” Econometrica 75 (1): 259–76.\n\n\nImbens, Guido W, Donald B Rubin, and Bruce I Sacerdote. 2001. “Estimating the Effect of Unearned Income on Labor Earnings, Savings, and Consumption: Evidence from a Survey of Lottery Players.” American Economic Review, 778–94.\n\n\nLaLonde, Robert J. 1986. “Evaluating the Econometric Evaluations of Training Programs with Experimental Data.” The American Economic Review, 604–20."
  },
  {
    "objectID": "03-NSW.html#prepare-the-data",
    "href": "03-NSW.html#prepare-the-data",
    "title": "\n3  LaLonde Male Samples\n",
    "section": "\n3.1 Prepare the Data",
    "text": "3.1 Prepare the Data\nFirst, the dataset is split into treatment and control groups by the treatment dummy. Note, two pretreatment variables (earnings in 1974 and employment status in 1974) are absent from this sample. We thus remove variables re74 (earnings in 1974), u74 (unemployment status in 1974), and tau (the treatment effect estimate) from the CPS-1 and PSID-1 datasets to match the structure of the treatment dataset.\n\nCode# source the functions provided in part 1\nsource(\"https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE\")\n\n\n\nCodeload(\"data/lalonde.RData\")\nload(\"data/trimmed.RData\")\ntreat &lt;- \"treat\"\nnsw_co$treat &lt;- 1\n\n# drop re74, u74, tau from cps1 and psid1\ncps1a &lt;- subset(cps1, select =  -c(re74, u74))\nnsw_cps &lt;- rbind.data.frame(nsw_tr, cps1a)\n\npsid1a &lt;- subset(psid1, select =  -c(re74, u74))\nnsw_psid &lt;- rbind.data.frame(nsw_tr, psid1a)\n\n\nnsw_cps.plus &lt;- rbind.data.frame(nsw_cps, nsw_co)\nnsw_psid.plus &lt;- rbind.data.frame(nsw_psid, nsw_co)"
  },
  {
    "objectID": "03-NSW.html#assessing-overlap",
    "href": "03-NSW.html#assessing-overlap",
    "title": "\n3  LaLonde Male Samples\n",
    "section": "\n3.2 Assessing Overlap",
    "text": "3.2 Assessing Overlap\nIn this step, we define variables for the outcome (Y = “re78”), treatment indicator (treat), and covariates that include age, education, race/ethnicity indicators, marital status, degree status, and earnings in 1975.\nAgain, we assess overlap in covariate distributions between treated and control groups based on the propensity score via GRF (log odds ratio) for the LDW-Experimental, LDW-CPS1, and LDW-PSID1 data.\n\nCode# define variables\nY &lt;- \"re78\"\ntreat &lt;- \"treat\"\ncovar &lt;- c(\"age\", \"education\", \"black\", \"hispanic\", \"married\", \"nodegree\", \"re75\", \"u75\")\n\n\n\n3.2.1 NSW-Experimental\nFigure: Experimental (male sample).\n\nCodensw_ps &lt;- assess_overlap(data = nsw, treat = treat, cov = covar, xlim = c(-2, 1.5))\n\n\n\nFIGURE B5 (SM). Subfigure A: LDW-Experimental.\n\n\n\n\n3.2.2 NSW-CPS1 and NSW-PSID1\n\nCodepar(mfrow = c(1,2))\nnsw_cps_ps &lt;- assess_overlap(data = nsw_cps, treat = treat, cov = covar, xlim = c(-15, 5))\nnsw_psid_ps &lt;- assess_overlap(data = nsw_psid, treat = treat, cov = covar, xlim = c(-15, 5))\n\n\n\nFIGURE B5 (SM). Subfigure B: NSW-CPS1. Subfigure C: NSW-PSID1."
  },
  {
    "objectID": "03-NSW.html#trimming-to-improve-overlap",
    "href": "03-NSW.html#trimming-to-improve-overlap",
    "title": "\n3  LaLonde Male Samples\n",
    "section": "\n3.3 Trimming to Improve Overlap",
    "text": "3.3 Trimming to Improve Overlap\nWe then trim the data to improve overlap in covariate distributions by removing units with poor overlap based on the propensity score. This step aims to refine the datasets to improve later causal inference. With the trimmed data, we can reassess overlap for each group.\nLike before, we start by assessing overlaps between the distributions of the treated and control groups based on log-odds derived from propensity scores.\n\nCodensw_cps.plus_ps &lt;- assess_overlap(data = nsw_cps.plus, treat = treat, cov = covar, xlim = c(-15, 5))\nnsw_psid.plus_ps &lt;- assess_overlap(data = nsw_psid.plus, treat = treat, cov = covar, xlim = c(-15, 5))\n\n\nThen, we proceed with trimming to improve the quality of the causal inference. After trimming, we would expect the distributions to align more closely - the treatment and control groups are more comparable according to their covariates.\n\nCodetrim &lt;- function(data, ps = \"ps_assoverlap\", threshold = 0.9) {\n  sub &lt;- data[which(data[, ps] &lt; threshold), ]\n  return(sub)\n}\n\n#Trim\nnsw_cps_trim &lt;- trim(nsw_cps.plus_ps, threshold = 0.85)\nnsw_psid_trim &lt;- trim(nsw_psid.plus_ps, threshold = 0.85)\n\n# cps data\n# excluding the experimental controls\nnsw_cps_trim_match &lt;- subset(nsw_cps_trim, sample %in% c(0,3) & ps_assoverlap)\n# re-estimate propensity scores and employ 1:1 matching\nnsw_cps_trim_match &lt;- psmatch(data = nsw_cps_trim_match, Y = \"re78\", treat = \"treat\", cov = covar)\n\n# psid data\n# excluding the experimental controls\nnsw_psid_trim_match &lt;- subset(nsw_psid_trim, sample %in% c(0,4) & ps_assoverlap)\n# re-estimate propensity scores and employ 1:1 matching\nnsw_psid_trim_match &lt;- psmatch(data = nsw_psid_trim_match, Y = \"re78\", treat = \"treat\", cov = covar)\n\n\n\nCode#cps\nnsw_trim_cps &lt;- subset(nsw_cps_trim, sample %in% c(0,0.5))\nnsw_trim_cps$treat[which(nsw_trim_cps$sample == 0.5)] &lt;- 0\n#psid\nnsw_trim_psid &lt;- subset(nsw_psid_trim, sample %in% c(0,0.5))\nnsw_trim_psid$treat[which(nsw_trim_psid$sample == 0.5)] &lt;- 0"
  },
  {
    "objectID": "03-NSW.html#reassessing-overlap",
    "href": "03-NSW.html#reassessing-overlap",
    "title": "\n3  LaLonde Male Samples\n",
    "section": "\n3.4 Reassessing Overlap",
    "text": "3.4 Reassessing Overlap\nThe propensity scores are reestimated after trimming.The plots below show good overlaps especially in the center, indicating an improved balance and common support between the treated and control groups. The before-after trimming comparison suggests that the trim effectively removes units that were less comparable.\n\nCodepar(mfrow = c(1,2))\n# cps data\nnsw_cps_trim_match_ps &lt;- assess_overlap(data = nsw_cps_trim_match, treat = treat, cov = covar, xlim = c(-3,3))\n\n# psid data\nnsw_psid_trim_match_ps &lt;- assess_overlap(data = nsw_psid_trim_match, treat = treat, cov = covar, xlim = c(-3,3))\n\n\n\nFIGURE B5 (SM). Subfigure D: Trimmed NSW-CPS1. Subfigure E: Trimmed NSW-PSID1."
  },
  {
    "objectID": "03-NSW.html#checking-covariate-balance",
    "href": "03-NSW.html#checking-covariate-balance",
    "title": "\n3  LaLonde Male Samples\n",
    "section": "\n3.5 Checking Covariate Balance",
    "text": "3.5 Checking Covariate Balance\nWe can also check covariate balance directly by love.plot(). As shown in the following figures, covariate overlap improves significantly in both samples post-trimming (matching).\n\nCode# cps data\nlove.plot(nsw_cps, nsw_cps_trim_match, treat = treat, covar = covar, title = \"Covariate Balance of NSW-CPS1\")\n\n# psid data\nlove.plot(nsw_psid, nsw_psid_trim_match, treat = treat, covar = covar, title = \"Covariate Balance of NSW-PSID1\")"
  },
  {
    "objectID": "03-NSW.html#estimating-the-att",
    "href": "03-NSW.html#estimating-the-att",
    "title": "\n3  LaLonde Male Samples\n",
    "section": "\n3.6 Estimating the ATT",
    "text": "3.6 Estimating the ATT\nThe table below presents the ATT estimates using the original LaLonde male sample, of which the LDW sample is a subset. Table shows that, with sufficient overlap, most estimators yield estimates within relatively narrow ranges when using either CPS-SSA-1 or PSID-1 as control groups. However, these estimates do not align with the experimental benchmarks, with most estimates being negative.\n\nCode# experimental\nout1 &lt;- estimate_all(nsw, \"re78\", \"treat\", covar)\nout2 &lt;- estimate_all(nsw_trim_cps, \"re78\", \"treat\", covar)\nout3 &lt;- estimate_all(nsw_trim_psid, \"re78\", \"treat\", covar)\n# nonexperimental\nout4 &lt;- estimate_all(nsw_cps, \"re78\", \"treat\", covar)\nout5 &lt;- estimate_all(nsw_psid, \"re78\", \"treat\", covar)\nout6 &lt;- estimate_all(nsw_cps_trim_match, \"re78\", \"treat\", covar)\nout7 &lt;- estimate_all(nsw_psid_trim_match, \"re78\", \"treat\", covar)\n\n\n\nCode# print the result\na &lt;- list(out4, out5, out6, out7)\nn &lt;- nrow(out1)\nsav &lt;- matrix(\"\", n+1, length(a)*3-1)\nfor (j in 1:length(a)) {\n    out &lt;- a[[j]]\n    n &lt;- nrow(out)\n    for (i in 2:(nrow(out)+1)) {\n        sav[i, j*3-2] &lt;- sprintf(\"%.2f\", out[i-1, 1])\n        sav[i, j*3-1] &lt;- paste0(\"(\", sprintf(\"%.2f\", out[i-1, 2]), \")\")\n    }\n}\nsav[1, 1] &lt;- sprintf(\"%.2f\", out1[1, 1])\nsav[1, 2] &lt;- paste0(\"(\", sprintf(\"%.2f\", out1[1, 2]), \")\")\nsav[1, 4] &lt;- sprintf(\"%.2f\", out1[1, 1])\nsav[1, 5] &lt;- paste0(\"(\", sprintf(\"%.2f\", out1[1, 2]), \")\")\nsav[1, 7] &lt;- sprintf(\"%.2f\", out2[1, 1])\nsav[1, 8] &lt;- paste0(\"(\", sprintf(\"%.2f\", out2[1, 2]), \")\")\nsav[1, 10] &lt;- sprintf(\"%.2f\", out3[1, 1])\nsav[1, 11] &lt;- paste0(\"(\", sprintf(\"%.2f\", out3[1, 2]), \")\")\ncolnames(sav) &lt;- c(\"NSW-CPS1\", \"\", \"\", \"NSW-PSID1\", \"\", \"\", \"NSW-CPS1 (PS Trimmed) \", \"\", \"\", \"NSW-PSID1 (PS Trimmed)\", \"\")\nrownames(sav) &lt;- c(\"Experimental Benchmark\", \"Difference-in-Means\", \"Regression\", \" Oaxaca Blinder\", \"GRF\", \"NN Matching\", \"PS Matching\", \"IPW\", \"CBPS\", \"Entropy Balancing\", \"DML-ElasticNet\", \"AIPW-GRF\")\nsav %&gt;% knitr::kable(booktabs=TRUE, caption = \" Table B4 in the Supplementary Materials (SM), ATT Estimates: LaLonde Male Sample\")\n\n\nTable B4 in the Supplementary Materials (SM), ATT Estimates: LaLonde Male Sample\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNSW-CPS1\n\n\nNSW-PSID1\n\n\nNSW-CPS1 (PS Trimmed)\n\n\nNSW-PSID1 (PS Trimmed)\n\n\n\n\nExperimental Benchmark\n886.30\n(488.14)\n\n886.30\n(488.14)\n\n806.06\n(488.59)\n\n620.04\n(667.69)\n\n\nDifference-in-Means\n-8870.31\n(408.30)\n\n-15577.57\n(508.12)\n\n-235.15\n(564.20)\n\n-3805.68\n(1158.27)\n\n\nRegression\n-792.15\n(479.67)\n\n-1581.11\n(718.80)\n\n-188.50\n(546.17)\n\n-3805.87\n(1228.97)\n\n\nOaxaca Blinder\n-726.42\n(462.50)\n\n-1215.01\n(481.08)\n\n-168.78\n(437.15)\n\n-4029.24\n(640.17)\n\n\nGRF\n-973.23\n(450.96)\n\n-2827.30\n(454.87)\n\n12.87\n(422.40)\n\n-3713.34\n(527.73)\n\n\nNN Matching\n-290.38\n(585.14)\n\n-1122.98\n(1210.25)\n\n36.05\n(631.36)\n\n-4793.26\n(1338.66)\n\n\nPS Matching\n-272.11\n(547.31)\n\n-1682.58\n(744.21)\n\n-145.53\n(557.97)\n\n-5116.83\n(1503.83)\n\n\nIPW\n-531.26\n(485.39)\n\n-2018.84\n(986.56)\n\n30.31\n(556.20)\n\n-4346.24\n(1382.71)\n\n\nCBPS\n-566.41\n(476.37)\n\n-718.81\n(888.13)\n\n-136.08\n(570.57)\n\n-3870.47\n(1320.64)\n\n\nEntropy Balancing\n-566.82\n(476.39)\n\n-691.85\n(889.21)\n\n-136.70\n(570.43)\n\n-3965.87\n(1339.89)\n\n\nDML-ElasticNet\n-787.03\n(479.32)\n\n-1673.83\n(722.32)\n\n-334.60\n(545.61)\n\n-3816.99\n(1216.93)\n\n\nAIPW-GRF\n-344.27\n(515.40)\n\n-1859.96\n(878.55)\n\n183.94\n(548.04)\n\n-4247.06\n(1346.55)\n\n\n\n\n\nThe table above lists the ATT estimates using different statistical methods to assess the impact of a treatment-job training program- on earnings in 1978 (re78). The results are shown for two control groups (CPS1 and PSID1) both before and after trimming based on propensity scores to improve the match between treated and control units. While the trimming generally moves the estimates closer to the experimental benchmark, estimates derived from observational data are generally lower (more negative) than the experimental benchmark."
  },
  {
    "objectID": "03-NSW.html#alternative-estimands-catt-and-qtet",
    "href": "03-NSW.html#alternative-estimands-catt-and-qtet",
    "title": "\n3  LaLonde Male Samples\n",
    "section": "\n3.7 Alternative Estimands: CATT and QTET",
    "text": "3.7 Alternative Estimands: CATT and QTET\n\n3.7.1 Conditional Average Treatment Effect on the Treated (CATT)\nThe figures below show the CATT estimates using the original LaLonde data (male sample).\nEach point on the scatter plots represents a pair of CATT estimates for a single unit: one from the experimental benchmark and one from the observational method. Points that lie on the 45-degree line (the red line) are cases where the observational and experimental methods yield the same estimate.\n\nCode# estimate catt\ncatt.nsw &lt;- catt(nsw, Y, treat, covar)\ncatt.cps &lt;- catt(nsw_cps, Y, treat, covar)\ncatt.psid &lt;- catt(nsw_psid, Y, treat, covar)\ncatt.cps.trim &lt;- catt(nsw_cps_trim_match, Y, treat, covar)\ncatt.psid.trim &lt;- catt(nsw_psid_trim_match, Y, treat, covar)\n# trimmed experimental data\ncatt.nsw.cps &lt;- catt(nsw_trim_cps, Y, treat, covar)\ncatt.nsw.psid &lt;- catt(nsw_trim_psid, Y, treat, covar)\n\n\n\nCodepar(mfrow = c(2,2))\n# plot catt - \"CATT (Experimental)\" and \"CATT (CPS-Full)\"\ncatt1 &lt;- catt.nsw$catt\natt1 &lt;- catt.nsw$att[1]\ncatt2 &lt;- catt.cps$catt\natt2 &lt;- catt.cps$att[1]\nplot_catt(catt1, catt2, att1, att2, \"CATT (Experimental)\", \"CATT (CPS-Full)\",\n          main = \"A. NSW-CPS1\", c(-8000, 8000))\n\n# plot catt - \"CATT (Experimental)\" and \"CATT (PSID-Full)\"\ncatt1 &lt;- catt.nsw$catt\natt1 &lt;- catt.nsw$att[1]\ncatt2 &lt;- catt.psid$catt\natt2 &lt;- catt.psid$att[1]\nplot_catt(catt1, catt2, att1, att2, \"CATT (Experimental)\", \"CATT (PSID-Full)\",\n    main = \"B. NSW-PSID1\", c(-8000, 8000))\n\n# plot catt - \"CATT (Experimental)\" and \"CATT (CPS-Trimmed)\"\ncatt1 &lt;- catt.nsw.cps$catt\natt1 &lt;- catt.nsw.cps$att[1]\ncatt2 &lt;- catt.cps.trim$catt\natt2 &lt;- catt.cps.trim$att[1]\nplot_catt(catt1, catt2, att1, att2, \"CATT (Experimental)\", \"CATT (CPS-Trimmed)\",\n    main = \"C. NSW-CPS1 Trimmed\", c(-8000, 8000))\n\n# plot catt - \"CATT (Experimental)\" and \"CATT (PSID-Trimmed)\"\ncatt1 &lt;- catt.nsw.psid$catt\natt1 &lt;- catt.nsw.psid$att[1]\ncatt2 &lt;- catt.psid.trim$catt\natt2 &lt;- catt.psid.trim$att[1]\nplot_catt(catt1, catt2, att1, att2, \"CATT (Experimental)\", \"CATT (PSID-Trimmed)\",\n    main = \"D. NSW-PSID1 Trimmed\", c(-8000, 8000))\n\n\n\nFIGURE B7. CATT Estimates for the LaLonde Data (Male Sample)\n\n\n\nNote: Scatterplots show the CATT using both experimental data (x-axis) and nonexperimental data (y-axis) from LaLonde (1986) (male sample). Each dot corresponds to a CATT estimate based on the covariate values of a treated unit, while each red cross symbolizes the ATT estimates. For every estimate, the AIPW estimator is employed, with the GRF approach for estimating nuisance parameters. Different subfigures indicate various data comparisons: Subfigure A: Compares Experimental with LaLonde-CPS1. Subfigure B: Compares Experimental with LaLonde-PSID1. Subfigure C: Compares trimmed Experimental (removing 30 treated units) against trimmed NSW-CPS1. Subfigure D: Compares trimmed Experimental (removing 150 treated units) to trimmed NSW-PSID1.\nBased on untrimmed data, Subfigure A and B show a wide dispersion of points around the 45-degree line. This raises our concern about the lack of agreement between the experimental benchmark and the CATT estimates from the CPS1 and PSID1 control groups.\nOn the other hand, after trimming based on propensity scores, the dispersion of points in Subfigure C and D is more concentrated around the 45-degree line, indicating that the agreement between the experimental benchmark and the CATT estimates has improved. The comparison suggests that trimming has successfully reduced bias in estimating the treatment effect by ensuring that the treated and control groups are more similar in covariates distributions.\n\n3.7.2 Quantile Treatment Effect on the Treated (QTET)\nThe Figures below show the quantile treatment effects on the treated in the original LaLonde male sample. QTET analysis helps us to see where along the outcome distribution the treatment is more or less effective. The code below consists of two main parts:\n\nThe est_qte function estimates the QTET.\nPlotting QTET: The plot_qte function creates the plots, with separate plots for each data comparison (NSW-CPS, NSW-CPS trimmed, NSW-PSID, and NSW-PSID trimmed).\n\n\nCode# estimate qte (some of the following lines are not run due to computational limitation)\nqte.nsw &lt;- est_qte(Y, treat, NULL, data = nsw)\nqte.nsw.cps &lt;- est_qte(Y, treat, NULL, data = nsw_trim_cps)\nqte.nsw.psid &lt;- est_qte(Y, treat, NULL, data = nsw_trim_psid)\n#qte.nsw_cps &lt;- est_qte(Y, treat, covar, data = nsw_cps) # adjusted\n#qte.nsw_cps0 &lt;- est_qte(Y, treat, NULL, data = nsw_cps) # unadjusted\nqte.nsw_cps.trim &lt;- est_qte(Y, treat, covar, data = nsw_cps_trim_match) # adjusted\nqte.nsw_cps.trim0 &lt;- est_qte(Y, treat, NULL, data = nsw_cps_trim_match) # unadjusted\n#qte.nsw_psid &lt;- est_qte(Y, treat, covar, data = nsw_psid) # adjusted\n#qte.nsw_psid0 &lt;- est_qte(Y, treat, NULL, data = nsw_psid) # unadjusted\nqte.nsw_psid.trim &lt;- est_qte(Y, treat, covar, data = nsw_psid_trim_match) # adjusted\nqte.nsw_psid.trim0 &lt;- est_qte(Y, treat, NULL, data = nsw_psid_trim_match) # unadjusted\n\n\n\nCode# plot qte\n\n#load the data\nload(\"data/qte_nsw.rds\")\n\npar(mfrow = c(2,2))\n# CPS\nplot_qte(qte.nsw_cps, qte.nsw_cps0, qte.nsw, main = \"NSW-CPS\", ylim = c(-25000, 15000))\nlegend(\"bottomleft\", legend = c(\"Experimental\", \"Unadjusted\", \"Adjusted\"), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = \"n\")\n\n## CPS trimmed\nplot_qte(qte.nsw_cps.trim, qte.nsw_cps.trim0, qte.nsw.cps, main = \"NSW-CPS (Trimmed)\", ylim = c(-25000, 15000))\nlegend(\"bottomleft\", legend = c(\"Experimental\", \"Unadjusted\", \"Adjusted\"), \n    lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = \"n\")\n\n# PSID\nplot_qte(qte.nsw_psid, qte.nsw_psid0, qte.nsw, main = \"NSW-PSID\", ylim = c(-25000, 15000))\nlegend(\"bottomleft\", legend = c(\"Experimental\", \"Unadjusted\", \"Adjusted\"), \n    lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = \"n\")\n\n# PSID trimmed\nplot_qte(qte.nsw_psid.trim, qte.nsw_psid.trim0, qte.nsw.psid, main = \"NSW-PSID (Trimmed)\", ylim = c(-25000, 15000))\nlegend(\"bottomleft\", legend = c(\"Experimental\", \"Unadjusted\", \"Adjusted\"), \n    lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = \"n\")\n\n\n\nFIGURE B8. Quantile Treatment Effects: Experimental vs. Nonexperimental\n\n\n\nNote: Figures show QTET using both experimental data (in blue) and nonexperimental data (in red for raw estimates and black for covariate-adjusted estimates). Each dot corresponds to a QTET estimate at a particular quantile, while shaded areas represent bootstrapped 95% confidence intervals. Unadjusted models do not incorporate covariates while adjustment models use the full set of covariates to estimate the propensity scores with a logit."
  },
  {
    "objectID": "03-NSW.html#sensitivity-analyses",
    "href": "03-NSW.html#sensitivity-analyses",
    "title": "\n3  LaLonde Male Samples\n",
    "section": "\n3.8 Sensitivity Analyses",
    "text": "3.8 Sensitivity Analyses\nBelow are our sensitivity analyses using the original LaLonde male sample, with results depicted in contour plots below.\n\nCodepar(mfrow = c(1,2))\n\n## datasets to be used: nsw, nsw_trim_cps, nsw_trim_psid\nY &lt;- \"re78\"\ntreat &lt;- \"treat\"\ncovar &lt;- c(\"age\", \"education\", \"black\", \"hispanic\", \"married\", \"nodegree\", \"re75\", \"u75\")\nbm &lt;- c(\"re75\")\n\n# trimmed NSW-CPS data\nsens_ana(nsw_trim_cps, Y, treat, covar, bm, kd = 1:3)\n\n# trimmed NSW-PSID data\nsens_ana(nsw_trim_psid, Y, treat, covar, bm, kd = 1)\n\n\n\nFIGURE B9. Sensitivity Analyses for Trimmed NSW-CPS1 and NSW-PSID1\n\n\n\nThe analyses suggest that the estimated training effect based on trimmed NSW-CPS is less sensitive to potential confounders compared to trimmed NSW-PSID.\n\n\n\n\nCalónico, Sebastian, and Jeffrey Smith. 2017. “The Women of the National Supported Work Demonstration.” Journal of Labor Economics 35 (S1): S65–97.\n\n\nDehejia, Rajeev H, and Sadek Wahba. 1999. “Causal Effects in Nonexperimental Studies: Reevaluating the Evaluation of Training Programs.” Journal of the American Statistical Association 94 (448): 1053–62.\n\n\n———. 2002. “Propensity Score-Matching Methods for Nonexperimental Causal Studies.” Review of Economics and Statistics 84 (1): 151–61.\n\n\nFirpo, Sergio. 2007. “Efficient Semiparametric Estimation of Quantile Treatment Effects.” Econometrica 75 (1): 259–76.\n\n\nImbens, Guido W, Donald B Rubin, and Bruce I Sacerdote. 2001. “Estimating the Effect of Unearned Income on Labor Earnings, Savings, and Consumption: Evidence from a Survey of Lottery Players.” American Economic Review, 778–94.\n\n\nLaLonde, Robert J. 1986. “Evaluating the Econometric Evaluations of Training Programs with Experimental Data.” The American Economic Review, 604–20."
  },
  {
    "objectID": "04-LCS.html#prepare-the-data",
    "href": "04-LCS.html#prepare-the-data",
    "title": "\n4  LCS Female Samples\n",
    "section": "\n4.1 Prepare the Data",
    "text": "4.1 Prepare the Data\nConsistent with LaLonde’s original analysis, the outcome variable is earnings in 1979 (re79). We use the same set of covariates as in LaLonde. Notably, this set does not include two pretreatment variables: earnings in 1974 and employment status in 1974. We also exclude the number of children in 1975 (nchildren75), which is available in the LCS dataset, from the covariates so that it can serve as a placebo outcome.\n\nCode# source the functions provided in part 1\nsource(\"https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE\")\n\n\n\nCodeload(\"data/lcs.RData\")\n\n# expc = 0: experimental treated; \n# expc = 1: experimental control; \n# expc = 2: psid control.\n\nlcs_psid$expc &lt;- 0 \nlcs_psid[lcs_psid$treat==0, ]$expc &lt;- 2 \nlcs_tr &lt;- lcs[lcs$treat==1, ]\nlcs_co &lt;- lcs[lcs$treat==0, ]\nlcs_co$treat &lt;-  1\nlcs_co$expc &lt;- 1\nlcs_psid.plus &lt;- rbind.data.frame(lcs_psid, lcs_co)"
  },
  {
    "objectID": "04-LCS.html#assessing-overlap",
    "href": "04-LCS.html#assessing-overlap",
    "title": "\n4  LCS Female Samples\n",
    "section": "\n4.2 Assessing Overlap",
    "text": "4.2 Assessing Overlap\nWe assess overlap in covariate distributions between treated and control groups based on the propensity score via GRF (log odds ratio) for the LCS-Experimental and LCS-PSID data.\n\nCode# define variables\nY &lt;- \"re79\"\ntreat &lt;- \"treat\"\n# redifine covariates: removing \"nchildren75\" to be used as placebo outcome\ncovar &lt;- c(\"age\", \"educ\", \"nodegree\", \"married\", \"black\", \"hisp\", \"re75\", \"u75\")\n\n\n\n4.2.1 LCS-Experimental and LCS-CPS1\nFigure B10 demonstrates overlap in the LDW using the propensity score estimated via GRF (log odds ratio).\n\nCodepar(mfrow = c(1,2))\nlcs_ps &lt;- assess_overlap(data = lcs, treat = treat, cov = covar, xlim = c(-1.5, 1.5), breaks = 40)\nlcs_psid_ps &lt;- assess_overlap(data = lcs_psid, treat = treat, cov = covar, xlim = c(-11, 7), breaks = 40)\n\n\n\nFIGURE B10 (SM). Subfigure A: LCS-Experimental. Subfigure B: LCS-PSID."
  },
  {
    "objectID": "04-LCS.html#trimming-to-improve-overlap",
    "href": "04-LCS.html#trimming-to-improve-overlap",
    "title": "\n4  LCS Female Samples\n",
    "section": "\n4.3 Trimming to Improve Overlap",
    "text": "4.3 Trimming to Improve Overlap\nWe then trim the data to improve overlap in covariate distributions by removing units with poor overlap based on the propensity score. This step aims to refine the datasets to improve later causal inference. With the trimmed data, we can reassess overlap for each group.\nLike before, we start by assessing overlaps between the distributions of the treated and control groups based on log-odds derived from propensity scores.\n\nCodelcs_psid.plus_ps &lt;- assess_overlap(data = lcs_psid.plus, treat = treat, cov = covar, xlim = c(-15, 5))\n\n\nThen, we proceed with trimming to improve the quality of the causal inference. After trimming, we would expect the distributions to align more closely - the treatment and control groups are more comparable according to their covariates.\n\nCodetrim &lt;- function(data, ps = \"ps_assoverlap\", threshold = 0.9) {\n  sub &lt;- data[which(data[, ps] &lt; threshold), ]\n  return(sub)\n}\n\n#Trim\nlcs_psid_trim &lt;- trim(lcs_psid.plus_ps, threshold = 0.9)\n\n# psid data: excluding the experimental controls\nlcs_psid_trim_match &lt;- subset(lcs_psid_trim, expc %in% c(0, 2) & ps_assoverlap)\n# re-estimate propensity scores and employ 1:1 matching\nlcs_psid_trim_match &lt;- psmatch(data = lcs_psid_trim_match, Y = \"re79\", treat = \"treat\", cov = covar)\n\n\n\nCode#psid: trim experimental data\nlcs_trim_psid &lt;- subset(lcs_psid_trim, expc %in% c(0, 1))\nlcs_trim_psid$treat[which(lcs_trim_psid$expc == 1)] &lt;- 0"
  },
  {
    "objectID": "04-LCS.html#reassessing-overlap",
    "href": "04-LCS.html#reassessing-overlap",
    "title": "\n4  LCS Female Samples\n",
    "section": "\n4.4 Reassessing Overlap",
    "text": "4.4 Reassessing Overlap\nThe propensity scores are reestimated after trimming.The plots below show good overlaps especially in the center, indicating an improved balance and common support between the treated and control groups. The before-after trimming comparison suggests that the trim effectively removes units that were less comparable.\n\nCode# psid data\nlcs_psid_trim_match_ps &lt;- assess_overlap(data = lcs_psid_trim_match, treat = treat, cov = covar, xlim = c(-3,3), breaks = 40)\n\n\n\nFIGURE B10 (SM). Subfigure C: Trimmed LCS-PSID."
  },
  {
    "objectID": "04-LCS.html#checking-covariate-balance",
    "href": "04-LCS.html#checking-covariate-balance",
    "title": "\n4  LCS Female Samples\n",
    "section": "\n4.5 Checking Covariate Balance",
    "text": "4.5 Checking Covariate Balance\nWe can also check covariate balance directly by love.plot().\n\nCodeload(\"data/lcs.RData\")\n# psid data\nlove.plot(lcs_psid, lcs_psid_trim_match, treat = treat, covar = covar, title = \"Covariate Balance of LCS-PSID1\")"
  },
  {
    "objectID": "04-LCS.html#estimating-the-att",
    "href": "04-LCS.html#estimating-the-att",
    "title": "\n4  LCS Female Samples\n",
    "section": "\n4.6 Estimating the ATT",
    "text": "4.6 Estimating the ATT\nTable B6 shows the ATT estimates using the reconstructed LaLonde female samples. Reconstructed PSID-1 is used as the nonexperimental control group. Figure B11 visualizes the ATT estimates.\nUsing the LCS female samples, we find that many modern methods yield estimates close to the experimental benchmarks, though standard errors are often quite large.\n\nCodeset.seed(1234)\nload(\"data/lcs.RData\") \n# experimental\nout1 &lt;- estimate_all(lcs, Y, \"treat\", covar)\nout2 &lt;- estimate_all(lcs_trim_psid, Y, \"treat\", covar)\n# no experimental\nout3 &lt;- estimate_all(lcs_psid, Y, \"treat\", covar)\nout4 &lt;- estimate_all(lcs_psid_trim, Y, \"treat\", covar)\n\n\n\nCode# print the result\na &lt;- list(out3, out4)\n# columns are samples\nn &lt;- nrow(out1) + 1   # add experimental benchmark\nsav &lt;- matrix(\"\", n, length(a)*3-1)\nfor (j in 1:length(a)) {\n    out &lt;- a[[j]]\n    for (i in 1: (n-1)) {\n        sav[i+1, j*3-2] &lt;- sprintf(\"%.0f\", out[i, 1])\n        sav[i+1, j*3-1] &lt;- paste0(\"(\", sprintf(\"%.0f\", out[i, 2]), \")\")    \n    }\n}\nsav[1, 1] &lt;- sprintf(\"%.0f\", out1[1, 1]) # full experimental\nsav[1, 4] &lt;- sprintf(\"%.0f\", out2[1, 1]) # trimmed experimental (PSID)\nsav[1, 2] &lt;- paste0(\"(\", sprintf(\"%.0f\", out1[1, 2]), \")\")    \nsav[1, 5] &lt;- paste0(\"(\", sprintf(\"%.0f\", out2[1, 2]), \")\")    \ncolnames(sav) &lt;- c(\"LCS-PSID\", \"\", \"\", \"LCS-PSID (PS Trimmed)\", \"\")\nrownames(sav) &lt;- c(\"Experimental Benchmark\", \"Difference-in-Means\", \"Regression\", \" Oaxaca Blinder\", \"GRF\", \"NN Matching\", \"PS Matching\", \"IPW\", \"CBPS\", \"Entropy Balancing\", \"DML-ElasticNet\", \"AIPW-GRF\")\nsav %&gt;% knitr::kable(booktabs=TRUE, caption = \"TABLE B6 in the Supplementary Materials (SM), ATT Estimates: Reconstructed LaLonde Female Samples\")\n\n\nTABLE B6 in the Supplementary Materials (SM), ATT Estimates: Reconstructed LaLonde Female Samples\n\n\n\n\n\n\n\n\n\n\nLCS-PSID\n\n\nLCS-PSID (PS Trimmed)\n\n\n\n\nExperimental Benchmark\n821\n(308)\n\n785\n(380)\n\n\nDifference-in-Means\n-4172\n(412)\n\n-804\n(422)\n\n\nRegression\n808\n(389)\n\n359\n(414)\n\n\nOaxaca Blinder\n1128\n(239)\n\n608\n(296)\n\n\nGRF\n918\n(238)\n\n395\n(296)\n\n\nNN Matching\n1037\n(531)\n\n443\n(519)\n\n\nPS Matching\n872\n(333)\n\n364\n(402)\n\n\nIPW\n1043\n(468)\n\n506\n(459)\n\n\nCBPS\n1217\n(429)\n\n670\n(435)\n\n\nEntropy Balancing\n1229\n(430)\n\n673\n(436)\n\n\nDML-ElasticNet\n814\n(388)\n\n411\n(410)\n\n\nAIPW-GRF\n1050\n(487)\n\n424\n(460)\n\n\n\n\n\n\nCodepar(mfrow = c(2,1))\nband &lt;- out1[1, 3:4]\nest &lt;- out1[1, 1]\nplot_coef(out3, band = band, line = est, ylim = c(-6000, 6000), main = \"(A) LCS-PSID\")\n\nband &lt;- out2[1, 3:4]\nest &lt;- out2[1, 1]\nplot_coef(out4, band = band, line = est, ylim = c(-6000, 6000), main = \"(B) Trimmed LCS-PSID\")\n\n\n\nFIGURE B11. ATT Estimates: Reconstructed LaLonde Female Sample"
  },
  {
    "objectID": "04-LCS.html#alternative-estimands-catt-and-qtet",
    "href": "04-LCS.html#alternative-estimands-catt-and-qtet",
    "title": "\n4  LCS Female Samples\n",
    "section": "\n4.7 Alternative Estimands: CATT and QTET",
    "text": "4.7 Alternative Estimands: CATT and QTET\n\n4.7.1 Conditional Average Treatment Effect on the Treated (CATT)\nThe figures below show the CATT estimates using the reconstructed LaLonde female samples.\nEach point on the scatter plots represents a pair of CATT estimates for a single unit: one from the experimental benchmark and one from the observational method. Points that lie on the 45-degree line (the red line) are cases where the observational and experimental methods yield the same estimate.\n\nCode# estimate catt\ncatt.lcs &lt;- catt(lcs, Y, treat, covar)\ncatt.lcs.psid &lt;- catt(lcs_trim_psid, Y, treat, covar) # trimmed experimental data\ncatt.psid &lt;- catt(lcs_psid, Y, treat, covar)\ncatt.psid.trim &lt;- catt(lcs_psid_trim, Y, treat, covar)\n\n\n\nCodepar(mfrow = c(1,2))\n# plot catt - \"CATT (Experimental)\" and \"CATT (PSID-Full)\"\npar(mar = c(4, 4, 1, 1))\ncatt1 &lt;- catt.lcs$catt\natt1 &lt;- catt.lcs$att[1]\ncatt2 &lt;- catt.psid$catt\natt2 &lt;- catt.psid$att[1]\nplot_catt(catt1, catt2, att1, att2, \"CATT (Experimental)\", \"CATT (PSID-Full)\",\n    main = \"\", c(-8000, 8000))\n\n# plot catt - \"CATT (Experimental)\" and \"CATT (PSID-Trimmed)\"\npar(mar = c(4, 4, 1, 1))\ncatt1 &lt;- catt.lcs.psid$catt\natt1 &lt;- catt.lcs.psid$att[1]\ncatt2 &lt;- catt.psid.trim$catt\natt2 &lt;- catt.psid.trim$att[1]\nplot_catt(catt1, catt2, att1, att2, \"CATT (Experimental)\", \"CATT (PSID-Trimmed)\",\n    main = \"\", c(-8000, 8000))\n\n\n\nFIGURE B12. CATT Estimates for the reconstructed LaLonde female samples\n\n\n\nNote: Scatterplots show the CATT using both experimental data (x-axis) and nonexperimental data (y-axis) from the reconstructed LaLonde female samples. Each dot corresponds to a CATT estimate based on the covariate values of a treated unit, while each red cross symbolizes the ATT estimates. For every estimate, the AIPW estimator is employed, with the GRF approach for estimating nuisance parameters. Different subfigures indicate various data comparisons: Subfigure A: Compares LCS-Experimental with LaLonde-PSID1. Subfigure B: Compares Trimmed LCS-Experimental to Trimmed LCS-PSID.\n\n4.7.2 Quantile Treatment Effect on the Treated (QTET)\nThe Figures below show the quantile treatment effects on the treated in reconstructed LaLonde female samples. QTET analysis helps us to see where along the outcome distribution the treatment is more or less effective.\n\nCode# estimate qte (some of the following lines are not run due to computational limitation)\n## experimental\nqte.lcs &lt;- est_qte(Y, treat, NULL, data = lcs)\nqte.lcs.psid &lt;- est_qte(Y, treat, NULL, data = lcs_trim_psid)\n## non-experimental\nqte.lcs_psid &lt;- est_qte(Y, treat, covar, data = lcs_psid) # adjusted\nqte.lcs_psid0 &lt;- est_qte(Y, treat, NULL, data = lcs_psid) # unadjusted\nqte.lcs_psid.trim &lt;- est_qte(Y, treat, covar, data = lcs_psid_trim) # adjusted\nqte.lcs_psid.trim0 &lt;- est_qte(Y, treat, NULL, data = lcs_psid_trim) # unadjusted\n\n\n\nCode# plot qte\npar(mfrow = c(1,2))\n\n# PSID\nplot_qte(qte.lcs_psid, qte.lcs_psid0, qte.lcs, main = \"LCS-PSID\", ylim = c(-25000, 15000))\nlegend(\"bottomleft\", legend = c(\"Experimental\", \"Unadjusted\", \"Adjusted\"), \n    lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = \"n\")\n\n# PSID trimmed\nplot_qte(qte.lcs_psid.trim, qte.lcs_psid.trim0, qte.lcs.psid, main = \"LCS-PSID (Trimmed)\", ylim = c(-25000, 15000))\nlegend(\"bottomleft\", legend = c(\"Experimental\", \"Unadjusted\", \"Adjusted\"), \n    lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = \"n\")\n\n\n\nFIGURE B13: Quantile Treatment Effects: Reconstructed Female Samples\n\n\n\nNote: Figures show the quantile treatment effects on the treated (QTET) using the reconstructed LaLonde female samples. Results from the experimental data are shown in blue and results from the nonexperimental data are shown in red for raw estimates and black for covariate-adjusted estimates. Each dot corresponds to a QTET estimate at a particular quantile, while shaded areas represent bootstrapped 95% confidence intervals. Unadjusted models do not incorporate covariates while adjustment models use the full set of covariates to estimate the propensity scores with a logit."
  },
  {
    "objectID": "04-LCS.html#placebo-tests",
    "href": "04-LCS.html#placebo-tests",
    "title": "\n4  LCS Female Samples\n",
    "section": "\n4.8 Placebo Tests",
    "text": "4.8 Placebo Tests\nWe conduct placebo analyses to further assess the plausibility of unconfoundedness. In the placebo analysis, estimators using observational data usually generate negative estimates. we fail to substantiate the unconfoundedness assumption with a placebo test using the number of children in 1975, a variable absent in LaLonde, as the placebo outcome.\n\nCodeY &lt;- \"nchildren75\"\ntreat &lt;- \"treat\"\ncovar &lt;- c(\"age\", \"educ\", \"nodegree\", \"married\", \"black\", \"hisp\", \"re75\", \"u75\")\n\n\nset.seed(1234)\n# experimental\nout1 &lt;- estimate_all(lcs, Y, \"treat\", covar)\nout2 &lt;- estimate_all(lcs_trim_psid, Y, \"treat\", covar)\n# no experimental\nout3 &lt;- estimate_all(lcs_psid, Y, \"treat\", covar)\nout4 &lt;- estimate_all(lcs_psid_trim, Y, \"treat\", covar)\n\n\n\nCode# print the result\na &lt;- list(out3, out4)\n# columns are samples\nn &lt;- nrow(out1) + 1   # add experimental benchmark\nsav &lt;- matrix(\"\", n, length(a)*3-1)\nfor (j in 1:length(a)) {\n    out &lt;- a[[j]]\n    for (i in 1: (n-1)) {\n        sav[i+1, j*3-2] &lt;- sprintf(\"%.2f\", out[i, 1])\n        sav[i+1, j*3-1] &lt;- paste0(\"(\", sprintf(\"%.2f\", out[i, 2]), \")\")    \n    }\n}\nsav[1, 1] &lt;- sprintf(\"%.2f\", out1[1, 1]) # full experimental\nsav[1, 4] &lt;- sprintf(\"%.2f\", out2[1, 1]) # trimmed experimental (PSID)\nsav[1, 2] &lt;- paste0(\"(\", sprintf(\"%.2f\", out1[1, 2]), \")\")    \nsav[1, 5] &lt;- paste0(\"(\", sprintf(\"%.2f\", out2[1, 2]), \")\")    \ncolnames(sav) &lt;- c(\"LCS-PSID\", \"\", \"\", \"LCS-PSID (PS Trimmed)\", \"\")\nrownames(sav) &lt;- c(\"Experimental Benchmark\", \"Difference-in-Means\", \"Regression\", \" Oaxaca Blinder\", \"GRF\", \"NN Matching\", \"PS Matching\", \"IPW\", \"CBPS\", \"Entropy Balancing\", \"DML-ElasticNet\", \"AIPW-GRF\")\nsav %&gt;% knitr::kable(booktabs=TRUE, caption = \"TABLE B7 in the Supplementary Materials (SM): Placebo Test: Number of Children in 1975 as the Outcome\")\n\n\nTABLE B7 in the Supplementary Materials (SM): Placebo Test: Number of Children in 1975 as the Outcome\n\n\n\n\n\n\n\n\n\n\nLCS-PSID\n\n\nLCS-PSID (PS Trimmed)\n\n\n\n\nExperimental Benchmark\n-0.05\n(0.08)\n\n-0.08\n(0.09)\n\n\nDifference-in-Means\n0.47\n(0.09)\n\n0.14\n(0.11)\n\n\nRegression\n-0.18\n(0.11)\n\n-0.05\n(0.12)\n\n\nOaxaca Blinder\n-0.22\n(0.06)\n\n-0.15\n(0.07)\n\n\nGRF\n-0.52\n(0.06)\n\n-0.36\n(0.07)\n\n\nNN Matching\n-0.71\n(0.14)\n\n-0.49\n(0.14)\n\n\nPS Matching\n-0.79\n(0.09)\n\n-0.46\n(0.12)\n\n\nIPW\n-0.69\n(0.15)\n\n-0.41\n(0.15)\n\n\nCBPS\n-0.27\n(0.14)\n\n-0.12\n(0.13)\n\n\nEntropy Balancing\n-0.27\n(0.14)\n\n-0.12\n(0.13)\n\n\nDML-ElasticNet\n-0.18\n(0.11)\n\n-0.03\n(0.12)\n\n\nAIPW-GRF\n-0.75\n(0.15)\n\n-0.51\n(0.14)\n\n\n\n\n\n\nCodepar(mfrow = c(2,1))\nband &lt;- out1[1, 3:4]\nest &lt;- out1[1, 1]\nplot_coef(out3, band = band, line = est, ylim = c(-1.5, 1), main = \"(A) LCS-PSID\")\n\nband &lt;- out2[1, 3:4]\nest &lt;- out2[1, 1]\nplot_coef(out4, band = band, line = est, ylim = c(-1.5, 1), main = \"(B) Trimmed LCS-PSID\")\n\n\n\nFIGURE B14. Placebo Test: Number of Children in 1975 as the Outcome"
  },
  {
    "objectID": "04-LCS.html#sensitivity-analyses",
    "href": "04-LCS.html#sensitivity-analyses",
    "title": "\n4  LCS Female Samples\n",
    "section": "\n4.9 Sensitivity Analyses",
    "text": "4.9 Sensitivity Analyses\nBelow are our sensitivity analyses using the reconstructed LaLonde female samples, with results depicted in contour plots below.\n\nCodepar(mfrow = c(1,2))\n\n# define variables\nY &lt;- \"re79\"\ntreat &lt;- \"treat\"\n# redifine covariates: removing \"nchildren75\" to be used as placebo outcome\ncovar &lt;- c(\"age\", \"educ\", \"nodegree\", \"married\", \"black\", \"hisp\", \"re75\", \"u75\")\nbm &lt;- c(\"re75\")\n\n# LCS-Experimental data\nsens_ana(lcs, Y, treat, covar, bm, kd = 1)\n\n# trimmed LCS-PSID data\nsens_ana(lcs_psid, Y, treat, covar, bm, kd = 1:3)\n\n\n\nFIGURE B15. Sensitivity Analyses for Trimmed LDW-CPS and LDW-PSID\n\n\n\nThe analysis shows that the estimated training effect based on LCS-PSID is sensitive to potential confounders that behave like re75.\n\n\n\n\nCalónico, Sebastian, and Jeffrey Smith. 2017. “The Women of the National Supported Work Demonstration.” Journal of Labor Economics 35 (S1): S65–97.\n\n\nDehejia, Rajeev H, and Sadek Wahba. 1999. “Causal Effects in Nonexperimental Studies: Reevaluating the Evaluation of Training Programs.” Journal of the American Statistical Association 94 (448): 1053–62.\n\n\n———. 2002. “Propensity Score-Matching Methods for Nonexperimental Causal Studies.” Review of Economics and Statistics 84 (1): 151–61.\n\n\nFirpo, Sergio. 2007. “Efficient Semiparametric Estimation of Quantile Treatment Effects.” Econometrica 75 (1): 259–76.\n\n\nImbens, Guido W, Donald B Rubin, and Bruce I Sacerdote. 2001. “Estimating the Effect of Unearned Income on Labor Earnings, Savings, and Consumption: Evidence from a Survey of Lottery Players.” American Economic Review, 778–94.\n\n\nLaLonde, Robert J. 1986. “Evaluating the Econometric Evaluations of Training Programs with Experimental Data.” The American Economic Review, 604–20."
  },
  {
    "objectID": "05-IRS.html#the-imbens-rubin-and-sacerdote-irs-lottery-data",
    "href": "05-IRS.html#the-imbens-rubin-and-sacerdote-irs-lottery-data",
    "title": "\n5  The Lottery Data\n",
    "section": "\n5.1 The Imbens, Rubin, and Sacerdote (IRS) Lottery Data",
    "text": "5.1 The Imbens, Rubin, and Sacerdote (IRS) Lottery Data\nWe now reanalyze the lottery data from Imbens, Rubin, and Sacerdote (2001), who carried out an original survey to investigate the impact of the size of lottery prizes in Massachusetts during the mid-1980s on the economic behavior of lottery players. The primary outcome is post-winning labor earnings.\nThere are three treatment and control groups. The control group, termed “non-winners,” consists of 259 season ticket holders who have won a small, one-time prize, ranging from $100 to $5,000 (in essence, they are one-time, minor winners). The treatment groups, labeled “big winners” (43 individuals) and “small winners” (194 individuals), are those who clinched a major prize.\n\nCode# source the functions provided in part 1\nsource(\"https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE\")\n\n\n\nCodeload(\"data/lottery.RData\")\nd$tr &lt;- d$winner\nd$tr1 &lt;- ifelse(d$bigwinner == 1, 1, 0) # big winner\nd$tr2 &lt;- ifelse(d$bigwinner == 0 & d$winner == 1, 1, 0) # small winner\nd$co &lt;- ifelse(d$winner == 0, 1, 0) # control\nd$college &lt;- ifelse(d$educ &gt;= 16, 1, 0)"
  },
  {
    "objectID": "05-IRS.html#assessing-overlap",
    "href": "05-IRS.html#assessing-overlap",
    "title": "\n5  The Lottery Data\n",
    "section": "\n5.2 Assessing Overlap",
    "text": "5.2 Assessing Overlap\nIn the subsequent analysis, we will consider labor earnings from seven post-lottery winning periods as the outcomes. These are denoted as \\(Y_{i,0}\\), …, \\(Y_{i,6}\\), where t = 0 represents the year of winning a lottery—recall that individuals in the control group also received a modest, one-time prize that year. We will treat the labor earnings from the three years immediately preceding the lottery win, i.e., \\(Y_{i,-3}\\), \\(Y_{i,-2}\\), \\(Y_{i,-1}\\), as well as their average, as placebo outcomes. The labor earnings from the three years before those, i.e., \\(Y_{i,-6}\\), \\(Y_{i,-5}\\), \\(Y_{i,-4}\\), will be used as covariates for adjustment, alongside a set of time-invariant pre-lottery-winning variables. These include the number of tickets purchased (tixbot), gender (male), employment status at the time of winning (workthen), age when the lottery was won (agew), total years of education (educ), and the presence of a college degree (college).\nFirst, we estimate the overlap between the two treatment groups(the big winner treatment group on the left & the smaller winner treatment group on the right) and the control group. The assess_overlap function will conveniently present the overlap between the control and the treated.\n\nCodepar(mfrow = c(1,2))\n# select big winner\n\ns1 &lt;- subset(d, tr1 == 1 | co == 1)\n\ns1$xearn.avg &lt;- apply(s1[, paste0(\"xearn.\", 4:6)], 1, mean) # avg pre outcome\ns1$yearn.avg &lt;- apply(s1[, paste0(\"yearn.\", 1:7)], 1, mean) # avg pst outcome\n\n# assess overlap\ntreat &lt;- \"tr\"\ncovar &lt;- c(\"tixbot\", \"male\", \"workthen\", \"agew\", \"educ\", \"college\",\n           \"xearn.1\", \"xearn.2\", \"xearn.3\", \"yearw\")\n\ns1_ps &lt;- assess_overlap(data = s1, treat = treat, cov = covar, xlim = c(-5.5, 1), ylim = c(-0.4, 0.4), breaks = 30)\n\n# select small winner\n\ns2 &lt;- subset(d, tr2 == 1 | co == 1)\n\ns2$xearn.avg &lt;- apply(s2[, paste0(\"xearn.\", 4:6)], 1, mean) # avg pre outcome\ns2$yearn.avg &lt;- apply(s2[, paste0(\"yearn.\", 1:7)], 1, mean) # avg pst outcome\n\n# assess overlap\n\ntreat &lt;- \"tr\"\ncovar &lt;- c(\"tixbot\", \"male\", \"workthen\", \"agew\", \"educ\", \"college\",\n           \"xearn.1\", \"xearn.2\", \"xearn.3\", \"yearw\")\n\ns2_ps &lt;- assess_overlap(data = s2, treat = treat, cov = covar, xlim = c(-3, 3), ylim = c(-0.2, 0.2), breaks = 30)\n\n\n\nFIGURE 7. SubfigureA:Big Winners vs Non-Winners. SubfigureB:Small Winners vs Non-Winners.\n\n\n\nThe figures indicate that while the propensity score distributions of individuals in the treatment groups differ from that of the control group, the propensity scores of the treatment groups still fall within the support of the control group."
  },
  {
    "objectID": "05-IRS.html#trimming-to-improve-overlap",
    "href": "05-IRS.html#trimming-to-improve-overlap",
    "title": "\n5  The Lottery Data\n",
    "section": "\n5.3 Trimming to Improve Overlap",
    "text": "5.3 Trimming to Improve Overlap\nTo improve overlap, we further trim the control group for each of the two treatment groups by implementing 1:1 matching based on propensity scores. Then, we reassess the overlap for the two trimmed datasets.\n\nCodepar(mfrow = c(1,2))\n# matching\n  ## In the matching procedure, we don't need Y actually, so just pick one Y to satisfy function's requirement\n\ns1_ps_match &lt;- psmatch(data = s1_ps, Y = \"yearn.2\", treat = treat, cov = covar)\n\n# assess overlap again\n\nss &lt;- assess_overlap(data = s1_ps_match, treat = treat, cov = covar, xlim = c(-1,1), breaks = 30)\n\n\n# matching\n  ## In the matching procedure, we don't need Y actually, so just pick one Y to satisfy function's requirement\n\ns2_ps_match &lt;- psmatch(data = s2_ps, Y = \"yearn.2\", treat = treat, cov = covar)\n\n# assess overlap again\n\nss &lt;- assess_overlap(data = s2_ps_match, treat = treat, cov = covar, xlim = c(-3,3), breaks = 30)\n\n\n\nFIGURE B16. Subfigure A: Big Winners vs Control. Subfigure B: Small Winners vs Control.\n\n\n\nFrom the histograms, trimming improved the overlap for the big winner treatment group but not for the small winner one. Here are a few points to consider.\nFirst, if the treatment and control groups have very different covariate distributions, it is difficult to achieve good overlap even after trimming. As the plots suggest, the big winner group likely had more control units that were similar to the treated units, making it easier to find matches.\nSecond, the small winner group’s log odds have a wide range before trimming and remain wide after trimming. This suggests that the small winner group might have more extreme values or outliers that are not present in the control group."
  },
  {
    "objectID": "05-IRS.html#att-and-placebo-estimates",
    "href": "05-IRS.html#att-and-placebo-estimates",
    "title": "\n5  The Lottery Data\n",
    "section": "\n5.4 ATT and Placebo Estimates",
    "text": "5.4 ATT and Placebo Estimates\nSince trimming does not significantly improve the overlap between the treated and the control, we will proceed with the original dataset.\n\nCode# prepare data again\n\nd$tr &lt;- d$winner\nd$tr1 &lt;- ifelse(d$bigwinner == 1, 1, 0) # big winner\nd$tr2 &lt;- ifelse(d$bigwinner == 0 & d$winner == 1, 1, 0) # small winner\nd$co &lt;- ifelse(d$winner == 0, 1, 0) # control\nd$college &lt;- ifelse(d$educ &gt;= 16, 1, 0)\n\ncolnames(d)[9:14] &lt;- paste0(\"x\", 1:6)\ncolnames(d)[15:21] &lt;- paste0(\"y\", 1:7)\nd$earnings_1yr_before &lt;- d$x6\n\nd$xearn.avg &lt;- apply(d[, paste0(\"x\", 4:6)], 1, mean) # avg pre outcome\nd$yearn.avg &lt;- apply(d[, paste0(\"y\", 1:7)], 1, mean) # avg pst outcome\n\ns1 &lt;- subset(d, tr1 == 1 | co == 1) # big winner\ns2 &lt;- subset(d, tr2 == 1 | co == 1) # small winner\n\n\n\nCode# estimate and placebo analyses\n\ncovar &lt;- c(\"tixbot\", \"male\", \"workthen\", \"agew\", \"educ\", \"college\",\n           \"x1\", \"x2\", \"x3\", \"yearw\")\n\n# big winners\nset.seed(1234)\nout1 &lt;- estimate_all(s1, \"yearn.avg\", \"tr\", covar)\n#out1\nout2 &lt;- estimate_all(s1, \"xearn.avg\", \"tr\", covar)\n#out2\n# small winners\nout3 &lt;- estimate_all(s2, \"yearn.avg\", \"tr\", covar)\n#out3\nout4 &lt;- estimate_all(s2, \"xearn.avg\", \"tr\", covar)\n#out4\n\n\n\nCodepar(mfrow = c(4,1))\nylim &lt;- c(-20, 20)\n\nplot_coef(out1, ylim = ylim, main = \"Big Winner vs. Non-Winner\", main.pos = 3)\n\nplot_coef(out2, ylim = ylim, main = \"Big Winner vs. Non-Winner: Placebo Test\", main.pos = 3)\n\nplot_coef(out3, ylim = ylim, main = \"Small Winner vs. Non-Winner\", main.pos = 3)\n\nplot_coef(out4, ylim = ylim, main = \"Small Winner vs. Non-Winner: Placebo Test\", main.pos = 3)\n\n\n\nFIGURE 8. ATT and Placebo Estimates: IRS Data\n\n\n\nThe ATT results are presented in the table below:\n\nCode# print the result\na &lt;- list(out1, out2, out3, out4)\nn &lt;- nrow(out1)\nsav &lt;- matrix(\"\", n, length(a)*3-1)\nfor (j in 1:length(a)) {\n    out &lt;- a[[j]]\n    n &lt;- nrow(out)\n    for (i in 1:(nrow(out))) {\n        sav[i, j*3-2] &lt;- sprintf(\"%.2f\", out[i, 1])\n        sav[i, j*3-1] &lt;- paste0(\"(\", sprintf(\"%.2f\", out[i, 2]), \")\")\n    }\n}\ncolnames(sav) &lt;- c(\"Big Prize: Post-Winning Average Earning\", \"\", \"\", \"Big Prize: Pre-Winning Average Earning\", \"\", \"\", \"Small Prize: Post-Winning Average Earning\", \"\", \"\", \"Small Prize: Pre-Winning Average Earning\", \"\")\nrownames(sav) &lt;- c(\"Difference-in-Means\", \"Regression\", \" Oaxaca Blinder\", \"GRF\", \"NN Matching\", \"PS Matching\", \"IPW\", \"CBPS\", \"Entropy Balancing\", \"DML-ElasticNet\", \"AIPW-GRF\")\nsav %&gt;% knitr::kable(booktabs=TRUE, caption = \" Table B8 in the Supplementary Materials (SM), ATT and Placebo Estimates: IRSData\")\n\n\nTable B8 in the Supplementary Materials (SM), ATT and Placebo Estimates: IRSData\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBig Prize: Post-Winning Average Earning\n\n\nBig Prize: Pre-Winning Average Earning\n\n\nSmall Prize: Post-Winning Average Earning\n\n\nSmall Prize: Pre-Winning Average Earning\n\n\n\n\nDifference-in-Means\n-8.33\n(2.13)\n\n-0.33\n(2.39)\n\n-5.41\n(1.37)\n\n-4.58\n(1.35)\n\n\nRegression\n-9.17\n(2.32)\n\n-0.87\n(1.36)\n\n-4.09\n(1.15)\n\n-0.46\n(0.59)\n\n\nOaxaca Blinder\n-9.49\n(2.66)\n\n-0.52\n(3.03)\n\n-3.20\n(1.15)\n\n0.30\n(1.20)\n\n\nGRF\n-8.17\n(2.62)\n\n-0.26\n(3.01)\n\n-2.41\n(1.13)\n\n-0.17\n(1.19)\n\n\nNN Matching\n-9.62\n(2.17)\n\n-0.53\n(1.32)\n\n-3.02\n(0.95)\n\n0.36\n(0.60)\n\n\nPS Matching\n-6.16\n(3.09)\n\n0.57\n(3.39)\n\n-4.40\n(1.39)\n\n-2.51\n(1.33)\n\n\nIPW\n-8.40\n(2.64)\n\n-0.79\n(2.85)\n\n-3.73\n(1.72)\n\n-2.23\n(1.73)\n\n\nCBPS\n-9.91\n(3.69)\n\n-0.55\n(3.53)\n\n-3.74\n(2.76)\n\n-1.23\n(2.49)\n\n\nEntropy Balancing\n-10.27\n(4.02)\n\n-0.64\n(3.80)\n\n-2.64\n(3.20)\n\n0.20\n(2.88)\n\n\nDML-ElasticNet\n-8.10\n(2.17)\n\n-0.81\n(1.28)\n\n-4.22\n(1.13)\n\n-0.49\n(0.57)\n\n\nAIPW-GRF\n-8.25\n(1.85)\n\n0.04\n(1.17)\n\n-2.42\n(0.95)\n\n0.18\n(0.53)\n\n\n\n\n\nUsing the original data, the above table presents both the ATT estimates and results from a placebo test using various estimators. Columns 1 and 2 compare “big winners” with the controls, while columns 3 and 4 compare “small winners” with the control. Columns 1 and 3 display the ATT estimates, with the outcome being the average annual labor earnings from Year 0 to Year 6. The results of the placebo test are reported in columns 2 and 4, where the placebo outcome is the average annual labor earnings from Year 3 to Year 1. The results indicate that various methods produce consistent results, which align with the findings reported in the original paper: winning a large prize leads to a significant decrease in labor income in the following years, averaging as much as $8,000 annually. In contrast, winning a smaller prize results in a more modest decline, averaging approximately $3,000 per year. Notably, when applying doubly robust estimators like AIPW-GRF, the placebo test estimates hover near zero, reinforcing the credibility of the unconfoundedness assumption."
  },
  {
    "objectID": "05-IRS.html#att-visualization",
    "href": "05-IRS.html#att-visualization",
    "title": "\n5  The Lottery Data\n",
    "section": "\n5.5 ATT Visualization",
    "text": "5.5 ATT Visualization\nWhile tables can enumerate the standard errors for each estimate, graphical visualization offer a more intuitive presentation of our findings. To facilitate a clearer understanding, we calculate and compare the ATT estimates derived from both the original and the matched dataset. The following code computes the difference-in-means alongside the AIPW-GRF estimates.\n\nCode# big winners\ns &lt;- s1_ps\ns2 &lt;- s1_ps_match\ncovar &lt;- c(\"tixbot\", \"male\", \"workthen\", \"agew\", \"educ\", \"college\", \n    \"xearn.1\", \"xearn.2\", \"xearn.3\", \"yearw\")\ntreat &lt;- \"tr\"\n# full dataset\noutcomes &lt;- c(paste0(\"xearn.\", 1:6), paste0(\"yearn.\", 1:7))\nest &lt;- vector(\"list\", length(outcomes))\nnames(est) &lt;- outcomes\nfor (i in 1:length(outcomes)) {\n    est[[i]] &lt;- estimate_all(s, outcomes[i], \"tr\", covar,\n    methods = c(\"diff\", \"aipw_grf\"))\n    #cat(i, \"\\n\")\n}\n# matched dataset\nest2 &lt;- vector(\"list\", length(outcomes))\nnames(est2) &lt;- outcomes\nfor (i in 1:length(outcomes)) {\n    est2[[i]] &lt;- estimate_all(s2, outcomes[i], \"tr\", covar,\n    methods = c(\"diff\", \"aipw_grf\"))\n    #cat(i, \"\\n\")\n}\n\n# Small winners\ns &lt;- s2_ps\ns2 &lt;- s2_ps_match\ncovar &lt;- c(\"tixbot\", \"male\", \"workthen\", \"agew\", \"educ\", \"college\", \n    \"xearn.1\", \"xearn.2\", \"xearn.3\", \"yearw\")\ntreat &lt;- \"tr\"\n# full dataset\noutcomes &lt;- c(paste0(\"xearn.\", 1:6), paste0(\"yearn.\", 1:7))\nest3 &lt;- vector(\"list\", length(outcomes))\nnames(est3) &lt;- outcomes\nfor (i in 1:length(outcomes)) {\n    est3[[i]] &lt;- estimate_all(s, outcomes[i], \"tr\", covar,\n    methods = c(\"diff\", \"aipw_grf\"))\n    #cat(i, \"\\n\")\n}\n# matched dataset\nest4 &lt;- vector(\"list\", length(outcomes))\nnames(est4) &lt;- outcomes\nfor (i in 1:length(outcomes)) {\n    est4[[i]] &lt;- estimate_all(s2, outcomes[i], \"tr\", covar,\n    methods = c(\"diff\", \"aipw_grf\"))\n    #cat(i, \"\\n\")\n}\n\n\nATT Results Visualization:\n\nCodepar(mfrow = c(2,1))\npar(mar = c(4, 4, 1, 2))\nplot(1, xlim = c(3.7, 13.3), ylim = c(-20, 10), type = \"n\", axes = FALSE, \n    ylab = \"Effects on Earnings (thousand USD)\", xlab = \"Year Relative to Winning\")\nbox(); axis(2)\naxis(1, at = 4:13, labels = c(-3:6))\nabline(h = 0, v= 6.5, col = \"gray60\", lty = 2, lwd = 2)\nfor (i in 4:13) {\n    # full dataset with DIM\n    lines(c(i-0.15, i-0.15), est[[i]][1,3:4], lty = 1, lwd = 2, col = \"grey60\") # CI\n    points(i-0.15, est[[i]][1,1], pch = 18, col = \"grey60\", cex = 1.2)  # Coef \n    # full dataset\n    lines(c(i, i), est[[i]][2,3:4], lwd = 2) # CI\n    points(i, est[[i]][2,1], pch = 16)  # Coef \n    # matched dataset\n    lines(c(i+0.15, i+0.15), est2[[i]][2,3:4], col = \"maroon\", lwd = 1.5) # CI\n    points(i+0.15, est2[[i]][2,1], col = \"maroon\", pch = 17)  # Coef  \n}\nlegend(\"topright\", legend = c(\"DIM,  Full (43: 259)\", \"AIPW, Full (43: 259)\", \n    \"AIPW, PS Matched (43: 43)\"), lwd = 2,\n    lty = c(1, 1, 1), pch = c(18, 16, 17), \n    col = c(\"grey50\", \"black\", \"maroon\"), bty = \"n\")\n\npar(mar = c(4, 4, 1, 2))\nplot(1, xlim = c(3.7, 13.3), ylim = c(-20, 10), type = \"n\", axes = FALSE, \n    ylab = \"Effects on Earnings (thousand USD)\", xlab = \"Year Relative to Winning\")\nbox(); axis(2)\naxis(1, at = 4:13, labels = c(-3:6))\nabline(h = 0, v= 6.5, col = \"gray60\", lty = 2, lwd = 2)\nfor (i in 4:13) {\n    # full dataset with DIM\n    lines(c(i-0.15, i-0.15), est3[[i]][1,3:4], lty = 1, lwd = 2, col = \"grey60\") # CI\n    points(i-0.15, est3[[i]][1,1], pch = 18, col = \"grey60\", cex = 1.2)  # Coef \n    # full dataset\n    lines(c(i, i), est3[[i]][2,3:4], lwd = 2) # CI\n    points(i, est3[[i]][2,1], pch = 16)  # Coef \n    # matched dataset\n    lines(c(i+0.15, i+0.15), est4[[i]][2,3:4], col = \"maroon\", lwd = 1.5) # CI\n    points(i+0.15, est4[[i]][2,1], col = \"maroon\", pch = 17)  # Coef  \n}\nlegend(\"topright\", legend = c(\"DIM,  Full (194: 259)\", \"AIPW, Full (194: 259)\", \n    \"AIPW, PS Matched (194: 194)\"), lwd = 2,\n    lty = c(1, 1, 1), pch = c(18, 16, 17), \n    col = c(\"grey50\", \"black\", \"maroon\"), bty = \"n\")\n\n\n\n9(A) and (B). ATT Estimates: IRS Data\n\n\n\nThe above figures show that in the comparison of “big winners” and “non-winners,” AIPW using the original or trimmed data produces estimates very similar to a simple difference-in-means estimator, suggesting minimal selection bias between the two groups. On the other hand, when comparing “small winners” with “non-winners,” the estimates from AIPW and difference-in-means diverge. However, findings from the former are much more credible than those from the latter because difference-in-means does not fare well in the placebo tests, whereas the former yields placebo estimates that are nearly 0."
  },
  {
    "objectID": "05-IRS.html#catt-estimates-and-visualization",
    "href": "05-IRS.html#catt-estimates-and-visualization",
    "title": "\n5  The Lottery Data\n",
    "section": "\n5.6 CATT Estimates and Visualization",
    "text": "5.6 CATT Estimates and Visualization\nTo assess the effects of the treatment, we proceed to evaluate the CATT, determined at the covariate values of the treated units. This assessment is conducted using the AIPW-GRF method for each of the ten outcomes within both the original big winners and the original small winners samples.\n\nCodedata &lt;- s1_ps\ntreat &lt;- \"tr\"\nntr &lt;- sum(data[, treat] == 1)\ntau &lt;- matrix(NA, ntr, length(outcomes))\natt &lt;- rep(NA, ntr)\nfor (i in 1:length(outcomes)) {\n    Y &lt;- outcomes[i]\n    catt.out &lt;- catt(data, Y, treat, covar)\n    tau[, i] &lt;- catt.out$catt\n    att[i] &lt;- catt.out$att[1]     \n    #cat(i, \"\\n\")\n}\n\ndata &lt;- s2_ps\ntreat &lt;- \"tr\"\nntr &lt;- sum(data[, treat] == 1)\ntau2 &lt;- matrix(NA, ntr, length(outcomes))\natt2 &lt;- rep(NA, ntr)\nfor (i in 1:length(outcomes)) {\n    Y &lt;- outcomes[i]\n    catt.out &lt;- catt(data, Y, treat, covar)\n    tau2[, i] &lt;- catt.out$catt\n    att2[i] &lt;- catt.out$att[1]     \n    #cat(i, \"\\n\")\n}\n\n\nIn both plots, the years before winning (Years -3, -2, and -1) serve as the placebo test period. In the years leading up to the win, the CATT estimates are expected to be around 0, which would suggest that the treatment (winning the lottery) has no effect in these years. The width of the violins indicates the density of the effect estimates — wider sections of the violin plot suggest that more data points are present at that effect size.\n\nCodepar(mfrow = c(2,1))\npar(mar = c(4, 4, 1, 2))\nplot(1, xlim = c(3.7, 13.3), ylim = c(-20, 10), type = \"n\", axes = FALSE, \n    ylab = \"Effects on Earnings (thousand USD)\", xlab = \"Year Relative to Winning\")\nbox(); axis(2)\naxis(1, at = 4:13, labels = c(-3:6))\nabline(h = 0, v= 6.5, col = \"gray60\", lty = 2, lwd = 1.5)\nfor (i in 4:length(outcomes)) {\n    dens &lt;- density(tau[,i], bw = 0.5)\n    polygon(i + dens$y, dens$x, col = \"#AAAAAA50\", border = NA)\n    lines(i + dens$y, dens$x, lwd = 1) \n    points(i+0.01,  att[i], pch = 16, cex = 0.8)  # Coef\n}\n\npar(mar = c(4, 4, 1, 2))\nplot(1, xlim = c(3.7, 13.3), ylim = c(-20, 10), type = \"n\", axes = FALSE, \n    ylab = \"Effects on Earnings (thousand USD)\", xlab = \"Year Relative to Winning\")\nbox(); axis(2)\naxis(1, at = 4:13, labels = c(-3:6))\nabline(h = 0, v= 6.5, col = \"gray60\", lty = 2, lwd = 1.5)\nfor (i in 4:length(outcomes)) {\n    dens &lt;- density(tau2[,i], bw = 0.5)\n    polygon(i + dens$y, dens$x, col = \"#AAAAAA50\", border = NA)\n    lines(i + dens$y, dens$x, lwd = 1) \n    points(i+0.01,  att2[i], pch = 16, cex = 0.8)  # Coef\n}\n\n\n\n9(C) and (D). CATT Estimates: IRS Data\n\n\n\nBeyond providing corroborative evidence for the placebo tests (i.e., CATT estimates align closely with 0 in the years leading up to the win as expected), the figures also reveal substantial treatment effect heterogeneity among lottery winners. In Post-Winning Years (Years 1 to 6), the effect of winning on earnings changes over time.\nNotably, the distributions of the CATT for many post-winning years appear bimodal. We observe two peaks in the distribution of the effects, which could suggest there are two different common outcomes or reactions to winning among the two treated groups."
  },
  {
    "objectID": "05-IRS.html#summary",
    "href": "05-IRS.html#summary",
    "title": "\n5  The Lottery Data\n",
    "section": "\n5.7 Summary",
    "text": "5.7 Summary\nOverall, we find that in the lottery study, the unconfoundedness assumption can be empirically validated through placebo tests, bolstering the credibility of the causal estimates. Importantly, the unconfoundedness assumption is much more believable in this study than in the LaLonde case because the inherent randomization of lotteries played a key role in treatment assignment, while supplementary covariates help account for discrepancies between treatment and control groups stemming from challenges like differential responses to the survey. The inclusion of six preceding outcomes also proves invaluable, as they likely explain both the selection mechanism and are highly correlated with the outcome variables; moreover, they also serve as good candidates for placebo outcomes, given their comparability to these outcomes.\n\n\n\n\nCalónico, Sebastian, and Jeffrey Smith. 2017. “The Women of the National Supported Work Demonstration.” Journal of Labor Economics 35 (S1): S65–97.\n\n\nDehejia, Rajeev H, and Sadek Wahba. 1999. “Causal Effects in Nonexperimental Studies: Reevaluating the Evaluation of Training Programs.” Journal of the American Statistical Association 94 (448): 1053–62.\n\n\n———. 2002. “Propensity Score-Matching Methods for Nonexperimental Causal Studies.” Review of Economics and Statistics 84 (1): 151–61.\n\n\nFirpo, Sergio. 2007. “Efficient Semiparametric Estimation of Quantile Treatment Effects.” Econometrica 75 (1): 259–76.\n\n\nImbens, Guido W, Donald B Rubin, and Bruce I Sacerdote. 2001. “Estimating the Effect of Unearned Income on Labor Earnings, Savings, and Consumption: Evidence from a Survey of Lottery Players.” American Economic Review, 778–94.\n\n\nLaLonde, Robert J. 1986. “Evaluating the Econometric Evaluations of Training Programs with Experimental Data.” The American Economic Review, 604–20."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Calónico, Sebastian, and Jeffrey Smith. 2017. “The Women of the\nNational Supported Work Demonstration.” Journal of Labor\nEconomics 35 (S1): S65–97.\n\n\nDehejia, Rajeev H, and Sadek Wahba. 1999. “Causal Effects in\nNonexperimental Studies: Reevaluating the Evaluation of Training\nPrograms.” Journal of the American Statistical\nAssociation 94 (448): 1053–62.\n\n\n———. 2002. “Propensity Score-Matching Methods for Nonexperimental\nCausal Studies.” Review of Economics and Statistics 84\n(1): 151–61.\n\n\nFirpo, Sergio. 2007. “Efficient Semiparametric Estimation of\nQuantile Treatment Effects.” Econometrica 75 (1):\n259–76.\n\n\nImbens, Guido W, Donald B Rubin, and Bruce I Sacerdote. 2001.\n“Estimating the Effect of Unearned Income on Labor Earnings,\nSavings, and Consumption: Evidence from a Survey of Lottery\nPlayers.” American Economic Review, 778–94.\n\n\nLaLonde, Robert J. 1986. “Evaluating the Econometric Evaluations\nof Training Programs with Experimental Data.” The American\nEconomic Review, 604–20."
  }
]